<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Manus 首款通用AI智能体</title>
    <url>/2025/03/07/Manus-%E9%A6%96%E6%AC%BE%E9%80%9A%E7%94%A8AI%E6%99%BA%E8%83%BD%E4%BD%93/</url>
    <content><![CDATA[<h1>做AI场景的知识分享，尤其是涉及头部的智能体平台，我前面主要介绍了Dify的使用，这里就不得不提这两天各种关于 Manus 炸裂的新闻。</h1>
<ul>
<li>
<h2 id="首先说清楚，我没拿到邀请码，申请的时候网站还崩了，所以我在官网看了下效果并查看了其他博主演示视频。">首先说清楚，我没拿到邀请码，申请的时候网站还崩了，所以我在官网看了下效果并查看了其他博主演示视频。</h2>
</li>
<li>
<h3 id="说说我的想法">说说我的想法</h3>
<ul>
<li>
<h3 id="第一点，Manus如果公测或者正式发布，效果不打折扣，那么它确实能从本质上帮助普通用户几乎没有门槛的使用AI技术。带来的可能是很多领域将实现技术平权。">第一点，Manus如果公测或者正式发布，效果不打折扣，那么它确实能从本质上帮助普通用户几乎没有门槛的使用AI技术。带来的可能是很多领域将实现技术平权。</h3>
</li>
<li>
<h3 id="再来说第二点，很快国内的大厂应该就会推出同类产品，市场将出现Agent技术的一次跃升。">再来说第二点，很快国内的大厂应该就会推出同类产品，市场将出现Agent技术的一次跃升。</h3>
<ul>
<li>从目前头部的几个集成平台说起：</li>
<li><strong>字节的扣子</strong>
<ul>
<li>积累了大量的开发者和插件，再加上火山引擎算力支持，完全有能力实现弯道超车。</li>
</ul>
</li>
<li><strong>Dify</strong><br>
一个可以私有化部署的开源框架，已经有很多企业和个人搭建了自己的AI平台，整合出一个通用Agent也是早晚得事。</li>
<li>再者还有腾讯的元宝或者说元器平台也是有机会的。</li>
<li>这里面因为Manus这种产品形态对算力要求太高了，所以大厂有资源不会放过这个机会。</li>
</ul>
</li>
</ul>
</li>
</ul>
<span id="more"></span>
<ul>
<li>
<h2 id="最后说下Manus的效果和启发：">最后说下Manus的效果和启发：</h2>
<ul>
<li>
<h4 id="Manus就像一个能力超群的全能助手，简单点就是：一句话他就可以接管你的电脑为你做：">Manus就像一个能力超群的全能助手，简单点就是：一句话他就可以接管你的电脑为你做：</h4>
<ul>
<li>商业研究</li>
<li>生活帮手</li>
<li>数据分析</li>
<li>教育可视化</li>
<li>以及各种提升生产率的工具</li>
</ul>
</li>
<li>
<p><strong>生活案例</strong>：规划4月去日本旅行(<strong>执行过程中还创建了日本旅游手册</strong>)</p>
<ul>
<li><a href="https://hfhfn.github.io/image_storage/html/%E6%97%A5%E6%9C%AC%E6%97%85%E6%B8%B8%E6%89%8B%E5%86%8C.html">日本旅游手册</a></li>
</ul>
</li>
<li>
<p><strong>生活分析案例</strong>：分析特斯拉的股票（<strong>创建了分析仪表板面</strong>）</p>
<ul>
<li><a href="https://pljclduq.manus.space/">特斯拉股票分析仪表板</a></li>
</ul>
</li>
<li>
<p><strong>教育展示案例</strong>：生成互动课程：<strong>动量定理</strong></p>
<ul>
<li><a href="https://hfhfn.github.io/image_storage/html/conservation_momentum/index.html">互动课程：动量定理</a></li>
</ul>
</li>
<li>
<p><strong>数据分析案例</strong>：雪松-西奈急救中心的人口和疾病患病率（<strong>只展示它分析中生成的图表，看看这图表的炸裂效果</strong>）</p>
<ul>
<li>
<div style="display: flex;">
  <img src="https://cdn.jsdelivr.net/gh/hfhfn/image_storage@img/img/disease_prevalence_comparison.png" alt="Image 1" style="width: 50%;">
  <img src="https://cdn.jsdelivr.net/gh/hfhfn/image_storage@img/img/disease_prevalence_chart.png" alt="Image 2" style="width: 50%;">
</div>
</li>
<li>
<div style="display: flex;">
  <img src="https://cdn.jsdelivr.net/gh/hfhfn/image_storage@img/img/population_distribution.png" alt="Image 1" style="width: 50%;">
  <img src="https://cdn.jsdelivr.net/gh/hfhfn/image_storage@img/img/neighborhood_disease_heatmap.png" alt="Image 2" style="width: 50%;">
</div>
</li>
<li>
<p><img src="https://cdn.jsdelivr.net/gh/hfhfn/image_storage@img/img/disease_by_neighborhood_3d.png" alt="disease_by_neighborhood_3d"></p>
</li>
</ul>
</li>
<li>
<h4 id="启发1：我观察到Manus执行任务时，它会在网络上进行大规模的信息检索，但它能力再强，海量的数据造成的AI幻觉和AI偏见会变得越来越难以避免。">启发1：我观察到Manus执行任务时，它会在网络上进行大规模的信息检索，但它能力再强，海量的数据造成的AI幻觉和AI偏见会变得越来越难以避免。</h4>
</li>
<li>
<h4 id="启发2：-或许我们不一定要去搭建自己的一个智能体，而是积累我们的大量知识库内容，等待大厂的通用Agent到来时，反而直接会被赋予更大的活力，真正实现更智能的交互和应用。">启发2： 或许我们不一定要去搭建自己的一个智能体，而是积累我们的大量知识库内容，等待大厂的通用Agent到来时，反而直接会被赋予更大的活力，真正实现更智能的交互和应用。</h4>
</li>
</ul>
</li>
</ul>
]]></content>
      <categories>
        <category>AI</category>
        <category>Agent</category>
      </categories>
      <tags>
        <tag>AI</tag>
        <tag>Agent</tag>
        <tag>Manus</tag>
        <tag>智能体</tag>
      </tags>
  </entry>
  <entry>
    <title>Hexo踩坑</title>
    <url>/2025/03/06/Hexo%E8%B8%A9%E5%9D%91/</url>
    <content><![CDATA[<hr>
<h1>一. 在 <strong>Hexo</strong> 博客中无法渲染数学公式，通常是因为 Hexo 默认不支持 LaTeX 公式渲染。你需要安装插件并配置 Hexo 以支持数学公式。以下是解决方案：</h1>
<hr>
<span id="more"></span>
<h3 id="方法-1：使用-hexo-renderer-markdown-it-和-markdown-it-katex">方法 1：使用 <code>hexo-renderer-markdown-it</code> 和 <code>markdown-it-katex</code></h3>
<ol>
<li>
<p><strong>卸载默认的 Markdown 渲染器</strong><br>
Hexo 默认使用 <code>hexo-renderer-marked</code>，它不支持 LaTeX 公式。你需要先卸载它：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">npm uninstall hexo-renderer-marked --save</span><br></pre></td></tr></table></figure>
</li>
<li>
<p><strong>安装 <code>hexo-renderer-markdown-it</code></strong><br>
这是一个更强大的 Markdown 渲染器，支持插件扩展：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">npm install hexo-renderer-markdown-it --save</span><br></pre></td></tr></table></figure>
</li>
<li>
<p><strong>安装 <code>markdown-it-katex</code> 插件</strong><br>
这个插件用于支持 LaTeX 公式渲染：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">npm install markdown-it-katex --save</span><br></pre></td></tr></table></figure>
</li>
<li>
<p><strong>配置 <code>_config.yml</code></strong><br>
在 Hexo 的配置文件 <code>_config.yml</code> 中添加以下内容：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">markdown:</span></span><br><span class="line">  <span class="attr">render:</span></span><br><span class="line">    <span class="attr">html:</span> <span class="literal">true</span></span><br><span class="line">    <span class="attr">xhtmlOut:</span> <span class="literal">false</span></span><br><span class="line">    <span class="attr">breaks:</span> <span class="literal">true</span></span><br><span class="line">    <span class="attr">linkify:</span> <span class="literal">true</span></span><br><span class="line">    <span class="attr">typographer:</span> <span class="literal">true</span></span><br><span class="line">    <span class="attr">quotes:</span> <span class="string">&#x27;“”‘’&#x27;</span></span><br><span class="line">  <span class="attr">plugins:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">markdown-it-katex</span></span><br></pre></td></tr></table></figure>
</li>
<li>
<p><strong>引入 KaTeX 的 CSS</strong><br>
在你的主题文件（例如 <code>themes/your-theme/layout/_partial/head.ejs</code>）中，添加以下代码以引入 KaTeX 的 CSS 文件：</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">link</span> <span class="attr">rel</span>=<span class="string">&quot;stylesheet&quot;</span> <span class="attr">href</span>=<span class="string">&quot;https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/katex.min.css&quot;</span>&gt;</span></span><br></pre></td></tr></table></figure>
</li>
<li>
<p><strong>重启 Hexo 服务器</strong><br>
重新启动 Hexo 服务器，查看公式是否正常渲染：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">hexo clean &amp;&amp; hexo server</span><br></pre></td></tr></table></figure>
</li>
</ol>
<hr>
<h3 id="方法-2：使用-hexo-renderer-pandoc（推荐）">方法 2：使用 <code>hexo-renderer-pandoc</code>（推荐）</h3>
<p>如果你需要更强大的数学公式支持（如复杂的 LaTeX 公式），可以使用 <code>hexo-renderer-pandoc</code>。</p>
<ol>
<li>
<p><strong>卸载默认的 Markdown 渲染器</strong><br>
卸载 Hexo 默认的渲染器：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">npm uninstall hexo-renderer-marked --save</span><br></pre></td></tr></table></figure>
</li>
<li>
<p><strong>安装 <code>hexo-renderer-pandoc</code></strong><br>
安装 Pandoc 渲染器：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">npm install hexo-renderer-pandoc --save</span><br></pre></td></tr></table></figure>
</li>
<li>
<p><strong>安装 Pandoc</strong><br>
你需要在本机安装 Pandoc。根据你的操作系统选择安装方式：</p>
<ul>
<li><strong>Windows</strong>: 下载并安装 <a href="https://pandoc.org/installing.html">Pandoc</a>。</li>
<li><strong>macOS</strong>: 使用 Homebrew 安装：<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">brew install pandoc</span><br></pre></td></tr></table></figure>
</li>
<li><strong>Linux</strong>: 使用包管理器安装，例如：<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">sudo</span> apt-get install pandoc</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li>
<p><strong>配置 <code>_config.yml</code></strong><br>
在 Hexo 的配置文件 <code>_config.yml</code> 中添加以下内容：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">markdown:</span></span><br><span class="line">  <span class="attr">render:</span></span><br><span class="line">    <span class="attr">html:</span> <span class="literal">true</span></span><br><span class="line">    <span class="attr">xhtmlOut:</span> <span class="literal">false</span></span><br><span class="line">    <span class="attr">breaks:</span> <span class="literal">true</span></span><br><span class="line">    <span class="attr">linkify:</span> <span class="literal">true</span></span><br><span class="line">    <span class="attr">typographer:</span> <span class="literal">true</span></span><br><span class="line">    <span class="attr">quotes:</span> <span class="string">&#x27;“”‘’&#x27;</span></span><br></pre></td></tr></table></figure>
</li>
<li>
<p><strong>重启 Hexo 服务器</strong><br>
重新启动 Hexo 服务器：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">hexo clean &amp;&amp; hexo server</span><br></pre></td></tr></table></figure>
</li>
</ol>
<hr>
<h3 id="方法-3：使用-hexo-filter-mathjax（简单但性能较差）">方法 3：使用 <code>hexo-filter-mathjax</code>（简单但性能较差）</h3>
<p>如果你不想折腾，可以使用 <code>hexo-filter-mathjax</code>，这是一个简单的插件，但性能较差。</p>
<ol>
<li>
<p><strong>安装插件</strong><br>
安装 <code>hexo-filter-mathjax</code>：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">npm install hexo-filter-mathjax --save</span><br></pre></td></tr></table></figure>
</li>
<li>
<p><strong>配置 <code>_config.yml</code></strong><br>
在 Hexo 的配置文件 <code>_config.yml</code> 中添加以下内容：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">mathjax:</span></span><br><span class="line">  <span class="attr">enable:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure>
</li>
<li>
<p><strong>重启 Hexo 服务器</strong><br>
重新启动 Hexo 服务器：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">hexo clean &amp;&amp; hexo server</span><br></pre></td></tr></table></figure>
</li>
</ol>
<hr>
<h3 id="测试公式">测试公式</h3>
<p>在你的博客文章中，使用以下语法测试公式：</p>
<ul>
<li>
<p>行内公式：<code>$E = mc^2$</code><br>
效果：<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>E</mi><mo>=</mo><mi>m</mi><msup><mi>c</mi><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">E = mc^2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.8141079999999999em;"></span><span class="strut bottom" style="height:0.8141079999999999em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.05764em;">E</span><span class="mrel">=</span><span class="mord mathit">m</span><span class="mord"><span class="mord mathit">c</span><span class="vlist"><span style="top:-0.363em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle uncramped"><span class="mord mathrm">2</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span></p>
</li>
<li>
<p>块级公式：<code>$$E = mc^2$$</code><br>
效果：</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>E</mi><mo>=</mo><mi>m</mi><msup><mi>c</mi><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">E = mc^2
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.8641079999999999em;"></span><span class="strut bottom" style="height:0.8641079999999999em;vertical-align:0em;"></span><span class="base displaystyle textstyle uncramped"><span class="mord mathit" style="margin-right:0.05764em;">E</span><span class="mrel">=</span><span class="mord mathit">m</span><span class="mord"><span class="mord mathit">c</span><span class="vlist"><span style="top:-0.413em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle uncramped"><span class="mord mathrm">2</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span></span></p>
</li>
</ul>
<hr>
<h3 id="总结">总结</h3>
<ul>
<li>如果你需要简单的公式支持，推荐使用 <strong>方法 1</strong>（<code>hexo-renderer-markdown-it</code> + <code>markdown-it-katex</code>）。</li>
<li>如果你需要更强大的公式支持，推荐使用 <strong>方法 2</strong>（<code>hexo-renderer-pandoc</code>）。</li>
<li>如果你不想折腾，可以使用 <strong>方法 3</strong>（<code>hexo-filter-mathjax</code>），但性能较差。</li>
</ul>
<h1>二. Hexo Admin后台新建posts，一直显示loading</h1>
<p>从错误信息来看，问题是由于 <code>js-yaml</code> 库的版本升级导致的。在 <code>js-yaml</code> 4.0.0 及以上版本中，<code>yaml.safeLoad</code> 方法已被移除，建议使用 <code>yaml.load</code> 方法代替。Hexo Admin 插件可能还在使用旧的 <code>yaml.safeLoad</code> 方法，因此导致了错误。</p>
<p>以下是解决该问题的步骤：</p>
<hr>
<h3 id="1-修改-Hexo-Admin-源码">1. <strong>修改 Hexo Admin 源码</strong></h3>
<ul>
<li>找到 Hexo Admin 插件中使用 <code>yaml.safeLoad</code> 的地方，将其替换为 <code>yaml.load</code>。</li>
<li>根据错误日志，问题出现在 <code>D:\AIGC\my_blog\node_modules\.pnpm\hexo-admin@2.3.0\node_modules\hexo-admin\api.js</code> 文件的第 44 行。</li>
<li>打开该文件，找到类似以下代码：<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">const</span> settings = yaml.<span class="title function_">safeLoad</span>(fs.<span class="title function_">readFileSync</span>(settingsPath, <span class="string">&#x27;utf8&#x27;</span>));</span><br></pre></td></tr></table></figure>
</li>
<li>将其修改为：<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">const</span> settings = yaml.<span class="title function_">load</span>(fs.<span class="title function_">readFileSync</span>(settingsPath, <span class="string">&#x27;utf8&#x27;</span>));</span><br></pre></td></tr></table></figure>
</li>
</ul>
<hr>
<h3 id="2-降级-js-yaml-版本">2. <strong>降级 <code>js-yaml</code> 版本</strong></h3>
<ul>
<li>如果你不想修改源码，可以尝试将 <code>js-yaml</code> 降级到 3.x 版本，该版本仍然支持 <code>yaml.safeLoad</code>。</li>
<li>运行以下命令：<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">npm install js-yaml@3.14.1 --save</span><br></pre></td></tr></table></figure>
</li>
<li>然后重新启动 Hexo 服务器。</li>
</ul>
<hr>
<h3 id="3-更新-Hexo-Admin-插件">3. <strong>更新 Hexo Admin 插件</strong></h3>
<ul>
<li>检查是否有新版本的 Hexo Admin 插件，可能已经修复了该问题。</li>
<li>运行以下命令更新插件：<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">npm install hexo-admin@latest --save</span><br></pre></td></tr></table></figure>
</li>
</ul>
<hr>
<h3 id="4-检查-Hexo-和插件兼容性">4. <strong>检查 Hexo 和插件兼容性</strong></h3>
<ul>
<li>确保 Hexo 和 Hexo Admin 插件的版本兼容。</li>
<li>查看 Hexo Admin 的官方文档或 GitHub 仓库，确认支持的 Hexo 版本。</li>
</ul>
<hr>
<h3 id="5-清理缓存并重启">5. <strong>清理缓存并重启</strong></h3>
<ul>
<li>清理 Hexo 缓存并重新生成静态文件：<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">hexo clean</span><br><span class="line">hexo generate</span><br></pre></td></tr></table></figure>
</li>
<li>重新启动 Hexo 服务器：<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">hexo server</span><br></pre></td></tr></table></figure>
</li>
</ul>
<hr>
<h3 id="6-检查-YAML-文件格式">6. <strong>检查 YAML 文件格式</strong></h3>
<ul>
<li>确保 Hexo Admin 使用的 YAML 配置文件格式正确，没有语法错误。</li>
<li>可以使用在线 YAML 校验工具（如 <a href="https://www.yamllint.com/">YAML Lint</a>）检查配置文件。</li>
</ul>
<hr>
<h3 id="7-全局替换-yaml-safeLoad">7. <strong>全局替换 <code>yaml.safeLoad</code></strong></h3>
<ul>
<li>如果你的项目中还有其他地方使用了 <code>yaml.safeLoad</code>，可以全局替换为 <code>yaml.load</code>。</li>
<li>使用代码编辑器的全局搜索功能，查找并替换所有 <code>yaml.safeLoad</code> 为 <code>yaml.load</code>。</li>
</ul>
<hr>
<h3 id="8-提交-Issue-给-Hexo-Admin">8. <strong>提交 Issue 给 Hexo Admin</strong></h3>
<ul>
<li>如果以上方法无效，建议到 Hexo Admin 的 GitHub 仓库提交 Issue，说明你的问题和环境信息（如 Hexo 版本、Node.js 版本等）。</li>
<li>Hexo Admin 仓库地址：<a href="https://github.com/hexojs/hexo-admin">https://github.com/hexojs/hexo-admin</a></li>
</ul>
<hr>
<h3 id="9-临时解决方案">9. <strong>临时解决方案</strong></h3>
<ul>
<li>如果你急需解决问题，可以暂时锁定 <code>js-yaml</code> 的版本为 3.x，在 <code>package.json</code> 中添加以下内容：<figure class="highlight json"><table><tr><td class="code"><pre><span class="line"><span class="attr">&quot;resolutions&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">  <span class="attr">&quot;js-yaml&quot;</span><span class="punctuation">:</span> <span class="string">&quot;3.14.1&quot;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>
</li>
<li>然后运行 <code>npm install</code> 重新安装依赖。</li>
</ul>
<hr>
<p>通过以上方法，你应该能够解决 <code>yaml.safeLoad</code> 被移除的问题。如果问题仍然存在，请提供更多上下文信息，我会进一步协助你排查问题。</p>
<h1>三.</h1>
]]></content>
      <categories>
        <category>自媒体</category>
        <category>博客</category>
      </categories>
      <tags>
        <tag>博客</tag>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title>RAG向量数据库原理与常用向量库</title>
    <url>/2025/03/11/RAG%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E5%8E%9F%E7%90%86%E4%B8%8E%E5%B8%B8%E7%94%A8%E5%90%91%E9%87%8F%E5%BA%93/</url>
    <content><![CDATA[<h3 id="在前面的课程中，我们已经学习了-RAG-检索流程中如何将文档数据解析、分块并转换为嵌入向量的操作。本节课将进一步掌握如何存储这些向量及其文档元数据，并高效地进行相似度检索。">在前面的课程中，我们已经学习了 RAG 检索流程中如何将文档数据解析、分块并转换为嵌入向量的操作。本节课将进一步掌握如何存储这些向量及其文档元数据，并高效地进行相似度检索。</h3>
<h3 id="在人工智能（AI）主导的时代，文字、图像、语音、视频等多模态数据的复杂性显著增加。由于这些数据具有非结构化和多维特征，向量表示能够有效表示语义和捕捉其潜在的语义关系，促使向量数据库成为存储、检索和分析高维数据向量的关键工具。">在人工智能（AI）主导的时代，文字、图像、语音、视频等多模态数据的复杂性显著增加。由于这些数据具有非结构化和多维特征，向量表示能够有效表示语义和捕捉其潜在的语义关系，促使向量数据库成为存储、检索和分析高维数据向量的关键工具。</h3>
<span id="more"></span>
<p><img src="https://cdn.jsdelivr.net/gh/hfhfn/image_storage@img/img/image-20250311110709348.png" alt="image-20250311110709348"></p>
<h4 id="下图展示了向量数据库的分类，依据是否开源与是否为专用向量数据库，将其分为四类。">下图展示了向量数据库的分类，依据是否开源与是否为专用向量数据库，将其分为四类。</h4>
<ol>
<li>第一类是开源的专用向量数据库，如 Chroma、Vespa、LanceDB、Marqo、Qdrant 和 Milvus，这些数据库专门设计用于处理向量数据。</li>
<li>第二类是支持向量搜索的开源数据库，如 OpenSearch、PostgreSQL、ClickHouse 和 Cassandra，它们是常规数据库，但支持向量搜索功能。</li>
<li>第三类是商用的专用向量数据库，如 Weaviate 和 Pinecone，它们专门用于处理向量数据，但属于商业产品或通过商业许可获得源码。</li>
<li>第四类是支持向量搜索的商用数据库，如 Elasticsearch、Redis、Rockset 和 SingleStore，这些常规数据库支持向量搜索功能，同时属于商业产品或可通过商业许可获得源码。</li>
</ol>
<p><img src="https://cdn.jsdelivr.net/gh/hfhfn/image_storage@img/img/image-20250311110911756.png" alt="image-20250311110911756"></p>
<h3 id="为什么需要向量数据库？">为什么需要向量数据库？</h3>
<p><strong>传统数据库通常分为关系型（SQL）数据库和非关系型（NoSQL）数据库</strong>，其中存储复杂、非结构化或半结构化信息的需求主要依赖于非关系型数据库的能力。<strong>图中展示了三种非关系型数据库类型与向量数据库</strong>：</p>
<p><img src="https://cdn.jsdelivr.net/gh/hfhfn/image_storage@img/img/image-20250311111250193.png" alt="image-20250311111250193"></p>
<ol>
<li>键值数据库（Key-Value）：通常用于简单的数据存储，通过键来快速访问数据。</li>
<li>文档数据库（Document）：用于存储文档结构的数据，如 JSON 格式。</li>
<li>图数据库（Graph）：用于表示和存储复杂的关系数据，常用于社交网络、推荐等场景。</li>
<li>向量数据库（Vector）：用于存储和检索基于向量表示的数据，用于 AI 模型的高维度和复杂的嵌入向量。</li>
</ol>
<h4 id="那在什么场景下该选择什么样的数据库呢？">那在什么场景下该选择什么样的数据库呢？</h4>
<ul>
<li>
<p>举个例子，如果你想要找到一本特定的书，只需通过书名来精准定位信息，键值数据库是最理想的选择。而如果你需要查询一本书的详细章节内容、作者简介等复杂的结构化信息，文档数据库则更为适用。</p>
</li>
<li>
<p>如果你的目标是了解书籍之间的推荐关系，或者探索作者之间的合作网络，图数据库可以高效存储和查询这些复杂的关系数据。</p>
</li>
<li>
<p>最后，如果你希望找到与某本书内容相似的书籍，比如基于主题、风格等特征进行相似性搜索，向量数据库则能够通过计算书籍内容语义在向量空间中的距离，为你提供语义最相关的数据信息。</p>
</li>
<li>
<p>向量数据库的核心在于其能够基于向量之间的相似性，快速、精确地定位和检索数据。这类数据库不仅为向量嵌入提供了优化的存储和查询功能，同时也继承了传统数据库的诸多优势，如性能、可扩展性和灵活性，满足了充分利用大规模数据的需求。相比之下，传统的基于标量的数据库由于无法应对数据复杂性和规模化处理的挑战，难以有效提取洞察并实现实时分析。</p>
</li>
</ul>
<h4 id="向量数据库的主要优势体现在以下几个方面：">向量数据库的主要优势体现在以下几个方面：</h4>
<ol>
<li>数据管理：向量数据库提供了易于使用的数据存储功能，如插入、删除和更新操作。与独立的向量索引工具（如 Faiss）相比，这使得向量数据的管理和维护更加简便，因为 Faiss 需要额外的工作才能与存储解决方案集成。</li>
<li>元数据存储和筛选：向量数据库能够<strong>存储与每个向量条目关联的元数据</strong>，用户可以基于这些元数据进行更细粒度的查询，从而提升查询的精确度和灵活性。</li>
<li>可扩展性：向量数据库设计旨在应对不断增长的数据量和用户需求，支持分布式和并行处理，并通过无服务器架构优化大规模场景下的成本。</li>
<li>实时更新：向量数据库通常支持实时数据更新，允许动态修改数据以确保检索结果的时效性和准确性。</li>
<li>备份与恢复：向量数据库具备完善的备份机制，能够处理数据库中所有数据的例行备份操作，确保数据的安全性与持久性。</li>
<li>生态系统集成：向量数据库能够与数据处理生态系统中的其他组件（如 ETL 管道中的 Spark、分析工具如 Tableau 和 Segment、可视化平台如 Grafana）轻松集成，从而简化数据管理工作流程。此外，它还能够无缝集成 AI 相关工具，如 <strong>LangChain、LlamaIndex</strong> 和 Cohere，进一步增强其应用潜力。</li>
<li>数据安全与访问控制：向量数据库通常提供内置的数据安全功能和访问控制机制，以保护敏感信息。通过命名空间实现的多租户管理，允许用户对索引进行完全分区，甚至可以在各自的索引中创建完全隔离的分区，确保数据的安全性和访问的灵活性。</li>
</ol>
<p>由于其上述特性，向量数据库可以广泛应用于 <strong>LLM RAG 系统</strong>、推荐系统、异常检测、计算机视觉、自然语言处理等多种 AI 产品生产场景中。</p>
<p>综上所述，向量数据库是一类专门为生产场景下的向量嵌入管理而构建的数据库。与传统的基于标量的数据库及独立的向量索引相比，向量数据库在性能、可扩展性、安全性和生态系统集成等方面展现了显著的优势，为现代数据管理提供了强有力的支持。</p>
<h4 id="向量数据库是如何工作的？">向量数据库是如何工作的？</h4>
<ul>
<li>
<p>向量数据库是一种专门用于存储和检索多维向量的数据库类型，与传统的基于行列结构的数据库不同，它主要处理高维空间中的数据点。<strong>传统数据库通常处理字符串、数字等标量数据，并通过<mark>精确匹配</mark>来查询数据</strong>。然而，<strong>向量数据库的操作逻辑则是基于<mark>相似性搜索</mark></strong>，即在查询时，应用特定的相似性度量（如余弦相似度、欧几里得距离等）来查找与查询向量最相似的向量。</p>
</li>
<li>
<p>向量数据库的核心在于其高效的索引和搜索机制。为了优化查询性能，它采用了如哈希、量化和基于图形的多种算法。这些算法通过构建如<strong>层次化可导航小世界（HNSW）图、产品量化（PQ）和位置敏感哈希（LSH）等索引结构</strong>，显著提升了查询速度。这种搜索过程并非追求绝对精确，而是<strong>通过近似最近邻（ANN）算法在速度与准确性之间进行权衡</strong>，从而实现快速响应。</p>
</li>
<li>
<p>向量数据库的索引结构可以理解为一种预处理步骤，类似于为图书馆中的书籍编制索引，方便快速找到所需内容。HNSW 图通过在多层结构中将相似向量连接在一起，快速缩小搜索范围。PQ 则通过压缩高维向量，减少内存占用并加速检索，而 LSH 则通过哈希函数将相似向量聚集在一起，便于快速定位。</p>
</li>
<li>
<p>向量数据库的搜索机制不是追求精确匹配，而是通过近似最近邻（ANN）算法在速度与准确性之间找到最佳平衡。ANN 算法通过允许一定程度的误差，在显著提高搜索速度的同时，依然能够找到与查询相似度较高的向量。这种策略对于需要实时、高精度响应的应用场景尤为重要。</p>
</li>
</ul>
<h5 id="向量数据库的工作流程涵盖了从向量存储、向量索引到最终检索的多环节操作，确保在复杂的数据环境中实现高效的存储、索引和相似性搜索。具体流程如下：">向量数据库的工作流程涵盖了从向量存储、向量索引到最终检索的多环节操作，确保在复杂的数据环境中实现高效的存储、索引和相似性搜索。具体流程如下：</h5>
<p><img src="https://cdn.jsdelivr.net/gh/hfhfn/image_storage@img/img/image-20250311112811861.png" alt="image-20250311112811861"></p>
<ol>
<li><strong>数据处理与向量化</strong>：原始数据首先被处理并转化为向量嵌入。这一步通过嵌入模型实现，模型利用深度学习算法提取数据的语义特征，生成适合后续处理的高维向量表示。</li>
<li><strong>向量存储</strong>：转化后的向量嵌入存储在数据库中。这一环节确保数据在高效检索的同时，能够以优化的方式管理和维护存储资源，以适应不同规模和复杂度的应用需求。</li>
<li><strong>向量索引</strong>：存储的向量嵌入需要经过索引处理，以便在后续查询中快速定位相关数据。索引过程通过构建特定的结构，使得数据库能够在大规模数据集上实现高效的查询响应。</li>
<li><strong>向量搜索</strong>：在接收到查询后，数据库通过已建立的索引结构执行相似性搜索，找出与查询向量最为接近的数据点。这一阶段的重点在于平衡搜索的速度与准确性，确保在大数据环境下提供快速且相关的查询结果。常见的向量搜索方法包括余弦相似度、欧几里得距离和曼哈顿距离。其中，<strong>余弦相似度主要用于文本处理和信息检索</strong>，关注向量之间的角度，以捕捉语义相似性；欧几里得距离则测量向量之间的实际距离，适用于密集特征集的聚类或分类；而曼哈顿距离则通过计算笛卡尔坐标中的绝对差值之和，适用于稀疏数据的处理。</li>
<li><strong>数据检索</strong>：最后，数据库从匹配的向量中检索出对应的原始数据，并根据特定的需求进行必要的后处理。这一步骤确保最终结果能够准确反映用户的查询意图，并提供有意义的输出。</li>
</ol>
<p>在 RAG 系统中，向量数据库起着重要的作用。其主要功能在于索引过程中，<strong>建立高效的向量索引结构</strong>，以便快速定位与查询相关的向量数据。在查询阶段，系统将输入的提示转化为向量表示形式，并从数据库中<strong>检索出与之最相关的向量及其对应的分块数据</strong>。通过这种索引和检索机制，检索到的向量为生成模型提供了必要的上下文信息，使模型能够依据当前的语义上下文生成更加精准和相关的响应。</p>
<p><img src="https://cdn.jsdelivr.net/gh/hfhfn/image_storage@img/img/image-20250311114141538.png" alt="image-20250311114141538"></p>
<h3 id="常用的向量数据库">常用的向量数据库</h3>
<p>下面列出十个目前主流的向量数据库，展示其数据库链接、介绍、优点与缺点。根据开发者具体的使用场景和技术需求，选择最适合的向量数据库解决方案是关键。</p>
<p><img src="https://cdn.jsdelivr.net/gh/hfhfn/image_storage@img/img/image-20250311114333810.png" alt="image-20250311114333810"></p>
<p>根据上面所示特点：</p>
<ul>
<li>对于需要快速开发和轻量化部署的项目，Chroma、Qdrant 是不错的选择。</li>
<li>而对于追求高性能和可扩展性的企业级应用，可以考虑 Milvus/Zilliz。</li>
<li>FAISS 是适合对性能有极致要求、不要求持久化和数据管理的场景。</li>
<li>Weaviate、LanceDB 在处理多模态数据方面表现突出，适用于需要管理多种数据类型（如图像、文本、音频等）的 AI 应用。</li>
<li>如果需要无缝集成现有数据库并进行向量搜索，PGVector、Elasticsearch、Redis 是理想的方案。</li>
<li>而不希望管理基础设施的用户则可以选择 Pinecone 这样的全托管服务。</li>
</ul>
<h3 id="向量数据库实战">向量数据库实战</h3>
<ul>
<li>
<p>在实战中，我们使用 Chroma 作为 RAG 项目的向量库，以替代原先无法持久化的 Faiss 库。</p>
</li>
<li>
<p>Chroma 是一种简单且易于持久化的向量数据库，它以轻量级、开箱即用的特性著称。Chroma 支持内存中操作和磁盘持久化，能够高效地管理和查询向量数据，非常适合快速集成和开发。其设计简洁且不需要复杂的配置，使开发者能够专注于核心功能的实现而无需担心底层存储的复杂性。</p>
</li>
</ul>
<ol>
<li>引入 Chroma 向量数据库 chromadb，引入 uuid 模块用于为每个文本块生成唯一的 ID。</li>
<li>在 main 方法中，创建了 Chroma 本地存储实例 client 和存储集合 collection，实例数据库存储在项目根目录 rag_learning/chroma_db 下，数据存储在 documents 集合中。</li>
<li>在 indexing_process 方法中，将文档切块后的文本块的 ID、嵌入向量和原始文本块内容存储到 ChromaDB 的 documents 集合中。</li>
<li>在 retrieval_process 方法中，使用 Chroma 向量数据库检索与查询（query）最相似的 top_k 个文本块。</li>
</ol>
]]></content>
      <categories>
        <category>AI</category>
        <category>RAG</category>
        <category>索引/检索</category>
      </categories>
      <tags>
        <tag>RAG</tag>
        <tag>向量数据库</tag>
        <tag>检索</tag>
        <tag>索引</tag>
      </tags>
  </entry>
  <entry>
    <title>RAG检索流程（一）：混合检索</title>
    <url>/2025/03/12/RAG%E6%A3%80%E7%B4%A2%E6%B5%81%E7%A8%8B%EF%BC%88%E4%B8%80%EF%BC%89%EF%BC%9A%E6%B7%B7%E5%90%88%E6%A3%80%E7%B4%A2/</url>
    <content><![CDATA[<h3 id="为什么需要混合检索？">为什么需要混合检索？</h3>
<p>我们本节课正式开始讲解 <strong>RAG 检索流程</strong>。当前主流的 RAG 检索方式主要采用<strong>向量检索（Vector Search）</strong>，通过语义相似度来匹配文本切块。这种方法在我们之前的课程中已经深入探讨过了。然而，向量检索并非万能，它在某些场景下无法替代<strong>传统关键词检索</strong>的优势。</p>
<p>例如，当你需要精准搜索某个订单 ID、品牌名称或地址，或者搜索特定人物或物品的名字（如伊隆·马斯克、iPhone 15）时，<strong>向量检索的<mark>准确性</mark>往往不如关键词检索</strong>。此外，当用户输入的<strong>问题非常简短</strong>，仅包含几个单词时，比如搜索缩写词或短语（如 RAG、LLM），<strong>语义匹配的效果也可能不尽理想</strong>。</p>
<p>这些正是传统关键词检索的优势所在。关键词检索（Keyword Search）在几个场景中表现尤为出色：<strong>精确匹配</strong>，如产品名称、姓名、产品编号；少量字符的匹配，用户习惯于输入几个关键词，而少量字符进行向量检索时效果可能较差；以及<strong>低频词汇的匹配</strong>，低频词汇往往承载了关键意义，如在“你想跟我去喝咖啡吗？”这句话中，“喝”“咖啡”比“你”“吗”更具重要性。</p>
<span id="more"></span>
<p><img src="https://cdn.jsdelivr.net/gh/hfhfn/image_storage@img/img/image-20250312122858648.png" alt="image-20250312122858648"></p>
<p>在上述案例中，虽然依靠<strong>关键词检索可以精确找到与“订单 12345”匹配的特定信息</strong>，<strong>但它无法提供与订单相关的更广泛上下文</strong>。另一方面，<strong>语义匹配</strong>虽然能够识别“订单”和“配送”等相关概念，但在处理具体的订单 ID 时，往往容易出错。</p>
<p><strong><mark>混合检索（Hybrid Search）通过结合关键词检索和语义匹配的优势</mark></strong>，可以首先利用关键词检索精确定位到“订单 12345”的信息，然后通过语义匹配扩展与该订单相关的其他上下文或客户操作的信息，例如“12 开头的订单、包装破损严重”等。这样不仅能够获取精确的订单详情，还能获得与之相关的额外有用信息。</p>
<p>在 RAG 检索场景中，<strong>首要目标是确保最相关的结果能够出现在候选列表中</strong>。向量检索和关键词检索各有其独特优势，混合检索通过结合这多种检索技术，弥补了各自的不足，提供了一种更加全面的搜索方案。</p>
<h3 id="混合检索（多路召回）">混合检索（多路召回）</h3>
<p>混合检索是指在检索过程中同时采用多种检索方式，并将各类检索结果进行融合，从而得到最终的检索结果。<strong>混合检索的优势在于能够充分利用不同检索方式的优点，弥补各自的不足，从而提升检索的准确性和效率</strong>。下图展示了混合检索的流程：</p>
<p><img src="https://cdn.jsdelivr.net/gh/hfhfn/image_storage@img/img/image-20250312133821822.png" alt="image-20250312133821822"></p>
<p>混合检索实际上并没有严格限定必须包含哪几种检索方式。这里我们以<strong>向量检索</strong>和<strong>关键词检索</strong>的组合为例，但实际上可以包含多种检索方式的组合。如果我们将其他搜索算法结合在一起，也同样可以称为“混合检索”。例如，可以将**知识图谱（graphRAG）**技术用于检索实体关系，并与向量检索技术相结合。</p>
<p>更多的 RAG 检索方式还包括多重提问检索、上下文压缩检索、集成检索、多向量检索、自查询检索等，每种检索方式说明如下：</p>
<p><img src="https://cdn.jsdelivr.net/gh/hfhfn/image_storage@img/img/image-20250312134208626.png" alt="image-20250312134208626"></p>
<p>上述方法均包含在 LangChain 的检索器模块 <strong>langchain.retrievers</strong> 中，具体详情可以查看 <a href="https://python.langchain.com/api_reference/langchain/retrievers.html">LangChain 检索器站点</a>。</p>
<p>混合检索后，我们需要对多个检索方式的检索结果进行综合排名。下节课会详细讲解重排序技术，这里我们简单了解一种更简单的方法来排序，称为<strong>递归折减融合（Reciprocal Rank Fusion, RRF）排序</strong>。RRF 是一种把来自不同检索方法的排名结果结合起来的技巧。它的基本思想是，如果一个文档在不同的检索结果中都排得比较靠前，那么它在综合排名中就应该得到更高的位置。</p>
<p>相比于复杂的重排序技术，RRF 的操作更加简单，不需要对每种检索结果进行复杂的调整或计算。它通过直接考虑文档在不同方法中的排名，快速生成一个合理的综合排名。这种方法非常适合那些需要快速融合多个检索结果的场景，短时间内得到一个有参考价值的排序。</p>
<p>选择何种检索技术，取决于开发者需要解决什么样的问题，系统的性能要求、数据的复杂性以及用户的搜索习惯等。针对具体需求选择合适的检索技术，能够最大化地提升 RAG 系统的效率和准确性。</p>
<h3 id="混合检索技术实战">混合检索技术实战</h3>
<p>在实战中，我们使用 <strong>rank_bm25</strong> 作为 RAG 项目的关键词搜索技术。BM25 是一种强大的关键词搜索算法，通过分析词频（TF）和逆向文档频率（IDF）来评估文档与查询的相关性。具体来说，BM25 检查查询词在文档中的出现频率，以及该词在所有文档中出现的稀有程度。<strong>如果一个词在特定文档中频繁出现，但在其他文档中较少见，那么 BM25 会将该文档评为高度相关。</strong></p>
<p>此外，BM25 还通过调整文档长度的影响，防止因文档长度不同而导致的词频偏差。正是这种结合了词频和文档长度平衡的机制，使得 BM25 在关键词搜索中能够提供精准的检索结果，在 RAG 项目中尤为有效。</p>
<p>需要安装的依赖库：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pip install -U pip jieba rank_bm25 chromadb langchain langchain_community sentence-transformers unstructured pdfplumber python-docx python-pptx markdown openpyxl pandas -i https://pypi.tuna.tsinghua.edu.cn/simple </span><br></pre></td></tr></table></figure>
<p>代码内容：</p>
<ol>
<li>引入了 rank_bm25 库中的 <strong>BM25Okapi</strong> 类，用于实现 BM25 算法的检索功能。</li>
<li>引入了 <strong>jieba</strong> 库，用于对中文文本进行分词处理，这对于 BM25 算法处理中文文本起关键作用。</li>
<li>在 <strong>retrieval_process</strong> 方法中，从 Chroma 的 collection 中提取所有存储的文档内容，并使用 jieba 对这些文档进行中文分词，将分词结果存储为 <strong>tokenized_corpus</strong>，为后续的 BM25 检索做准备。</li>
<li>利用分词后的文档集合实例化 BM25Okapi 对象，并对查询语句进行分词处理。</li>
<li>计算查询语句与每个文档之间的 BM25 相关性得分 (bm25_scores)，然后选择得分最高的前 top_k 个文档，并提取这些文档的内容。</li>
<li>返回合并后的全部检索结果，包含向量检索和 BM25 检索的结果。（下节内容会引入重排序，这里只做简单顺序合并）</li>
</ol>
]]></content>
      <categories>
        <category>AI</category>
        <category>RAG</category>
        <category>检索</category>
        <category>混合检索</category>
      </categories>
      <tags>
        <tag>RAG</tag>
        <tag>检索</tag>
        <tag>混合检索</tag>
      </tags>
  </entry>
  <entry>
    <title>RAG索引（三）：嵌入（Embedding）技术</title>
    <url>/2025/03/10/RAG%E7%B4%A2%E5%BC%95%EF%BC%88%E4%B8%89%EF%BC%89%EF%BC%9A%E5%B5%8C%E5%85%A5%EF%BC%88Embedding%EF%BC%89%E6%8A%80%E6%9C%AF/</url>
    <content><![CDATA[<h3 id="嵌入模型（Embedding-Model）负责将文本数据映射到高维向量空间中，将输入的文档片段转换为对应的嵌入向量（embedding-vectors）。这些向量捕捉了文本的语义信息，并被存储在向量库（VectorStore）中，以便后续检索使用。用户查询（Query）同样通过嵌入模型的处理生成查询嵌入向量，这些向量用于在向量数据库中通过向量检索（Vector-Retrieval）匹配最相似的文档片段。根据不同的场景需求，评估并选择最优的嵌入模型，以确保-RAG-的检索性能符合要求。"><mark>嵌入模型（Embedding Model）负责将文本数据映射到高维向量空间中</mark>，将输入的文档片段转换为对应的嵌入向量（embedding vectors）。这些向量捕捉了文本的语义信息，并被存储在向量库（VectorStore）中，以便后续检索使用。<mark>用户查询（Query）同样通过嵌入模型的处理生成查询嵌入向量</mark>，这些向量用于在向量数据库中通过向量检索（Vector Retrieval）匹配最相似的文档片段。根据不同的场景需求，<mark>评估并选择最优的嵌入模型</mark>，以确保 RAG 的检索性能符合要求。</h3>
<span id="more"></span>
<img src="https://cdn.jsdelivr.net/gh/hfhfn/image_storage@img/img/%E5%B5%8C%E5%85%A5%E6%A8%A1%E5%9E%8B%E4%BD%9C%E7%94%A8.png" alt="嵌入模型作用" style="zoom: 67%;" />
<ul>
<li>
<h4 id="什么是Embedding嵌入？">什么是Embedding嵌入？</h4>
<ul>
<li>Embedding 嵌入是指将文本、图像、音频、视频等形式的信息映射为高维空间中的密集向量表示。这些向量在语义空间中起到坐标的作用，捕捉对象之间的语义关系和隐含的意义。通过在向量空间中进行计算（例如余弦相似度），可以量化和衡量这些对象之间的<strong>语义相似性</strong>。</li>
<li>在具体实现中，嵌入的每个维度通常对应文本的某种特征，例如性别、类别、数量等。通过多维度的数值表示，计算机能够理解并解析文本的复杂语义结构。例如，“man”和“woman”在描述性别维度上具有相似性，而“king”和“queen”则在性别和王室身份等维度上表现出相似的语义特征。</li>
<li>向量是一组在高维空间中定义点的数值数组，而<strong>嵌入则是将信息（如文本）转化为这种向量表示的过程</strong>。这些向量能够捕捉数据的语义及其他重要特征，使得语义相近的对象在向量空间中彼此邻近，而语义相异的对象则相距较远。<strong>向量检索（Vector Retrieval）是一种基于向量表示的搜索技术</strong>，通过计算查询向量与已知文本向量的相似度来识别最相关的文本数据。向量检索的高效性在于，它能在大规模数据集中快速、准确地找到与查询最相关的内容，这得益于向量表示中蕴含的丰富语义信息。</li>
<li>
<img src="https://cdn.jsdelivr.net/gh/hfhfn/image_storage@img/img/image-20250310112108258.png" alt="image-20250310112108258" style="zoom: 80%;" />
</li>
</ul>
</li>
<li>
<h4 id="Embedding-Model-嵌入模型">Embedding Model 嵌入模型</h4>
<ul>
<li>自 2013 年以来，word2vec、GloVe、fastText 等嵌入模型通过分析大量文本数据，学习得出单词的嵌入向量。近年来，随着 transformer 模型的突破，嵌入技术以惊人的速度发展。BERT、RoBERTa、ELECTRA 等模型将词嵌入推进到上下文敏感的阶段。这些模型在为文本中的每个单词生成嵌入时，会充分考虑其上下文环境，因此同一个单词在不同语境下的嵌入向量可以有所不同，从而大大提升了模型理解复杂语言结构的能力。</li>
<li>在 RAG 系统中，Embedding Model 嵌入模型扮演着关键角色，负责将文本数据映射到高维向量空间，以便高效检索和处理。具体而言，<strong>Embedding Model 将输入的文档片段（Chunks）和查询文本（Query）转换为嵌入向量（Vectors）</strong>，这些向量捕捉了文本的语义信息，并可在向量空间中与其他嵌入向量进行比较。</li>
<li>在 RAG 流程中，文档首先被分割成多个片段，每个片段随后通过 Embedding Model 进行嵌入处理。生成的文档嵌入向量被存储在 VectorStore 中，供后续检索使用。用户查询会通过 Embedding Model 转换为查询嵌入向量，这些向量用于在向量数据库中匹配最相似的文档片段，最终组合生成指令（Prompt），大模型生成回答。</li>
<li>
<img src="https://cdn.jsdelivr.net/gh/hfhfn/image_storage@img/img/image-20250310112648314.png" alt="image-20250310112648314" style="zoom:80%;" />
</li>
<li>正如图中所示，嵌入模型是 RAG 流程的核心。既然如此重要，市面上有非常多的嵌入模型，我们该如何为我们的业务场景选择最合适的嵌入模型呢？</li>
</ul>
</li>
<li>
<h4 id="Embedding-Model-嵌入模型评估与选择">Embedding Model 嵌入模型评估与选择</h4>
<ul>
<li>在选择适合的嵌入模型时，需要综合考虑多个因素，包括<strong>特定领域的适用性、检索精度、支持的语言、文本块长度、模型大小以及检索效率</strong>等因素。同时以广泛受到认可的 **MTEB（Massive Text Embedding Benchmark）和 C-MTEB（Chinese Massive Text Embedding Benchmark）**榜单作为参考，通过涵盖分类、聚类、语义文本相似性、重排序和检索等多个数据集的评测，开发者可以根据不同任务的需求，评估并选择最优的向量模型，以确保在特定应用场景中的最佳性能。</li>
<li>
<img src="https://cdn.jsdelivr.net/gh/hfhfn/image_storage@img/img/image-20250310113405164.png" alt="image-20250310113405164" style="zoom:80%;" />
</li>
<li><a href="https://huggingface.co/spaces/mteb/leaderboard">MTEB &amp; C-MTEB 榜单</a></li>
<li>
<img src="https://cdn.jsdelivr.net/gh/hfhfn/image_storage@img/img/image-20250310122014515.png" alt="image-20250310122014515" style="zoom:80%;" />
</li>
<li>榜单每日更新，可以切换语言为 中文，可以看到中文嵌入模型的排名。由于 RAG 是一项检索任务，我们需要按“Retrieval Average”（检索平均值）列对排行榜进行排序，图中显示的就是检索任务效果排序后的结果。在检索任务中，我们需要在榜单顶部看到最佳的检索模型，并且专注于以下几个关键列：</li>
<li><strong>Retrieval Average 检索平均值</strong>：较高的检索平均值表示模型更擅长在检索结果列表中将相关项目排在较高的位置，检索效果更好。</li>
<li><strong>Model Size 模型大小</strong>：模型的大小（以 GB 为单位）。虽然检索性能随模型大小而变化，但要注意，模型大小也会对延迟产生直接影响。因此，在选择模型时，建议筛选掉那些在硬件资源有限的情况下不可行的过大模型。在生产环境中，性能与效率之间的权衡尤为重要。</li>
<li><strong>Max Tokens 最大 Token 数</strong>：可压缩到单个文本块中的最大 Token 数。因为文档块我们希望不要过大而降低目标信息块的精准度，因此，即使最大 tokens 数为 512 的模型在大部分场景下也足够使用。</li>
<li><strong>Embedding Dimensions：嵌入向量的维度</strong>。越少的嵌入维度提供更快的推理速度，存储效率更高，而更多的维度可以捕获数据中的细微特征。我们需要在模型的性能和效率之间取得良好的权衡。</li>
<li><strong>实验至关重要</strong>，在排行榜上表现良好的模型不一定在你的任务上表现良好，试验各种高得分的模型至关重要。我们参考 MTEB 排行榜，选择多个适合我们场景的嵌入模型作为备选，并在我们的业务场景数据集上进行评估测试，以选出最适合我们 RAG 系统的嵌入模型。</li>
</ul>
</li>
<li>
<h4 id="Embedding-Model-技术实战">Embedding Model 技术实战</h4>
<ul>
<li>
<p>我们可以使用 SentenceTransformers 作为加载嵌入模型的 Python 模块。</p>
</li>
<li>
<p>SentenceTransformers（又名 SBERT）是一个用于训练和推理文本嵌入模型的 Python 模块，可以在 RAG 系统中计算嵌入向量。使用 SentenceTransformers 进行文本嵌入转换非常简单：只需导入模块库、加载模型，并调用 encode 方法即可。执行时，SentenceTransformers 会自动下载相应的模型库，当然也可以手动下载并指定模型库的路径。所有可用的模型都可以在 <a href="https://www.sbert.net/docs/sentence_transformer/pretrained_models.html">SentenceTransformers 模型库</a> 查看，超过 8000 个发布在 Hugging Face 上的嵌入模型库可以被使用。</p>
</li>
<li>
<p>在中文领域，智源研究院的 <a href="https://huggingface.co/collections/BAAI/bge-66797a74476eb1f085c7446d">BGE 系列模型</a> 是较为知名的开源嵌入模型，在 C-MTEB 上表现出色。BGE 系列目前包含 23 个嵌入模型，涵盖多种维度、多种最大 Token 数和模型大小，用户可以根据需求进行测试和使用。</p>
</li>
<li>
<p><strong>load_embedding_model 方法中使用 SentenceTransformer 加载嵌入模型代码</strong>：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 绝对路径：SentenceTransformer读取绝对路径下的bge-large-zh-v1.5模型，如需使用其他模型，下载其他模型，并且更换绝对路径即可</span></span><br><span class="line">embedding_model = SentenceTransformer(os.path.abspath(<span class="string">&#x27;data/bge-large-zh-v1.5&#x27;</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 自动下载：SentenceTransformer库自动下载BAAI/bge-large-zh-v1.5模型，如需下载其他模型，输入其他模型名称即可</span></span><br><span class="line"><span class="comment"># embedding_model = SentenceTransformer(&#x27;BAAI/bge-large-zh-v1.5&#x27;)</span></span><br></pre></td></tr></table></figure>
</li>
<li>
<p><strong>indexing_process 方法中将文本转化为嵌入向量代码</strong>：</p>
 <figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 文本块转化为嵌入向量列表，normalize_embeddings表示对嵌入向量进行归一化，用于后续流程准确计算向量相似度</span></span><br><span class="line">embeddings = []</span><br><span class="line"><span class="keyword">for</span> chunk <span class="keyword">in</span> all_chunks:</span><br><span class="line">      embedding = embedding_model.encode(chunk, normalize_embeddings=<span class="literal">True</span>)</span><br><span class="line">      embeddings.append(embedding)</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li>
<h4 id="总结">总结</h4>
<ul>
<li>嵌入技术将文本数据映射到高维向量空间中，捕捉其语义信息，支持向量检索，从而在大规模数据中快速识别与查询最相关的文档片段。在选择嵌入模型时，需要综合考虑特定领域的适用性、检索精度、支持的语言、文本块长度、模型大小以及检索效率等因素。</li>
<li>通过参考 MTEB 和 C-MTEB 的评测榜单，可以评估多个高得分的模型，并在具体的业务场景中进行测试，最终选择最适合该场景的嵌入模型。同时，使用 SentenceTransformers Python 模块可以简化嵌入模型的加载和嵌入计算，进而高效率集成测试。</li>
</ul>
</li>
</ul>
]]></content>
      <categories>
        <category>AI</category>
        <category>RAG</category>
        <category>索引</category>
        <category>嵌入（Embedding）技术</category>
      </categories>
      <tags>
        <tag>RAG</tag>
        <tag>索引</tag>
        <tag>嵌入</tag>
        <tag>embedding</tag>
      </tags>
  </entry>
  <entry>
    <title>RAG索引（一）：文档解析技术</title>
    <url>/2025/03/07/RAG%E7%B4%A2%E5%BC%95%EF%BC%88%E4%B8%80%EF%BC%89%EF%BC%9A%E6%96%87%E6%A1%A3%E8%A7%A3%E6%9E%90%E6%8A%80%E6%9C%AF/</url>
    <content><![CDATA[<h1>RAG索引流程中面临的文档解析任务</h1>
<h2 id="1-文档解析现状">1. 文档解析现状</h2>
<ul>
<li>文档解析技术的本质在于将格式各异、版式多样、元素多种的文档数据，包括段落、表格、标题、公式、多列、图片等文档区块，转化为阅读顺序正确的字符串信息。</li>
<li>高质量的文档解析能够从各种复杂格式的非结构化数据中提取出高精准度的信息，对 RAG 系统最终的效果起决定性的作用。</li>
<li>RAG应用场景中涉及的数据类型通常有：PDF、TXT、Word、PPT、Excel、CSV、Markdown、XML、HTML以及关系型和非关系型数据库等，这里面最常见也是最难的就是PDF的解析。</li>
<li>PDF 文档往往篇幅巨大、页数众多，且企业及专业领域 PDF 文件数据量庞大，因此文档解析技术还需具备极高的处理性能，以确保知识库的高效构建和实时更新。</li>
<li><img src="https://cdn.jsdelivr.net/gh/hfhfn/image_storage@img/img/image-20250307075848111.png" alt="image-20250307075848111"></li>
</ul>
<span id="more"></span>
<h2 id="2-文档解析工具选择（这里主要讨论开源工具）">2. 文档解析工具选择（这里主要讨论开源工具）</h2>
<ul>
<li>
<h3 id="我们可以把所有工具分为两大类">我们可以把所有工具分为两大类</h3>
<ul>
<li>一个是<strong>基于规则</strong>的开源库</li>
<li>一个是<strong>基于深度学习</strong>的开源库</li>
<li><img src="https://cdn.jsdelivr.net/gh/hfhfn/image_storage@img/img/image-20250307080819281.png" alt="image-20250307080819281"></li>
</ul>
</li>
<li>
<h4 id="这里我们首先介绍基于规则的解析工具">这里我们首先介绍基于规则的解析工具</h4>
<ul>
<li>因为我们选择的框架langchain提供在实际应用场景中常见文档格式基于规则的解析方案，涵盖 PDF、TXT、Word、PPT、Excel、CSV、Markdown、XML 和 HTML 格式。</li>
<li>所以初步使用<strong>langchain</strong>框架LangChain Document Loaders 文档加载器进行操作，也就是<strong>langchain_community.document_loaders</strong>模块。</li>
<li><img src="https://cdn.jsdelivr.net/gh/hfhfn/image_storage@img/img/image-20250307081912468.png" alt="image-20250307081912468"></li>
<li>以下是langchain Document Loader 所需的文档解析依赖库</li>
<li><img src="https://cdn.jsdelivr.net/gh/hfhfn/image_storage@img/img/image-20250307082205941.png" alt="image-20250307082205941"></li>
<li>例如，当我们项目中使用 from langchain_community.document_loaders import PDFPlumberLoader 时，需要先通过命令行 pip install pdfplumber 安装 pdfplumber 库。某些特殊情况下，还需要额外的依赖库，比如使用 UnstructuredMarkdownLoader 时，需要安装 unstructured 库来提供底层文档解析，还需要 markdown 库来支持 Markdown 文档格式更多能力。此外，对于像 .doc 这种早期的文档类型，还需要安装 libreoffice 软件库才能进行解析。</li>
<li>针对PDF文档，目前主流是转为MarkDown文件格式。PDF 文件分为电子版和扫描版，**PDF 电子版可以通过规则解析，提取出文本、表格等文档元素。**目前，有许多开源库可以支持，例如 pyPDF2、PyMuPDF、pdfminer、pdfplumber 和 papermage 等。这些库在 langchain_community.document_loaders 中基本都有对应的加载器。</li>
<li><strong>在基于规则的开源库中，pdfplumber 对中文支持较好，且在表格解析方面表现优秀，但对双栏文本的解析能力较差；pdfminer 和 PyMuPDF 对中文支持良好，但表格解析效果较弱；pyPDF2 对英文支持较好，但中文支持较差；papermage 集成了 pdfminer 和其他工具，特别适合处理论文场景。开发者可以根据实际业务场景的测试结果选择合适的工具，pdfplumber 或 pdfminer 都是当前不错的选择。</strong></li>
</ul>
</li>
<li>
<h4 id="再来看基于深度学习的开源解析工具">再来看基于深度学习的开源解析工具</h4>
<ul>
<li>基于深度学习的工具基本都是因PDF而生，无论扫描版还是电子版均需进行版面分析和阅读顺序的还原，将内容解析为一个包含所有文档元素并且具有正确阅读顺序的 MarkDown 文件。单纯依赖规则解析是无法实现这一目标的，目前支持这些功能的多为基于深度学习的开源库，如 Layout-parser、PP-StructureV2、PDF-Extract-Kit、pix2text、MinerU、marker 等。</li>
<li>由于深度学习模型的部署复杂性以及对显卡配置的要求，langchain目前基本集成的都是基于规则的解析工具，基于深度学习的工具需要进行独立部署。</li>
<li><img src="https://cdn.jsdelivr.net/gh/hfhfn/image_storage@img/img/image-20250307083713327.png" alt="image-20250307083713327"></li>
<li>除了以上提到的还有比如：RapidLayout 专注于版面分析的，以及众多专注OCR（光学字符识别）识别的ZeroX，GOT-OCR2.0, OCRmyPDF，olmOCR等。</li>
</ul>
</li>
<li>
<p>目前除了这些工具，采用 <strong>端到端的多模态大模型直接解析</strong> 包括文字模态以及图片中非文字内容的解析，如常见的折线图、柱状图等，也许是文档解析的终极形式，但模型在效率和成本方面仍存在挑战，但其未来潜力巨大，值得期待。</p>
</li>
</ul>
]]></content>
      <categories>
        <category>AI</category>
        <category>RAG</category>
        <category>索引</category>
        <category>文档解析</category>
      </categories>
      <tags>
        <tag>RAG</tag>
        <tag>文档解析</tag>
        <tag>langchain_community.document_loaders</tag>
        <tag>pdfplumber</tag>
        <tag>unstructured</tag>
      </tags>
  </entry>
  <entry>
    <title>RAG索引（二）：分块策略</title>
    <url>/2025/03/09/RAG%E7%B4%A2%E5%BC%95%EF%BC%88%E4%BA%8C%EF%BC%89%EF%BC%9A%E5%88%86%E5%9D%97%E7%AD%96%E7%95%A5/</url>
    <content><![CDATA[<h3 id="文档数据（Documents）经过解析后，通过分块技术将信息内容划分为适当大小的文档片段（chunks），从而使-RAG-系统能够高效处理和精准检索这些片段信息。">文档数据（Documents）经过解析后，通过分块技术将信息内容划分为适当大小的文档片段（chunks），从而使 RAG 系统能够高效处理和精准检索这些片段信息。</h3>
<h3 id="选择适合特定场景的分块策略是提升-RAG-系统召回率的关键。">选择适合特定场景的分块策略是提升 RAG 系统召回率的关键。</h3>
<ul>
<li>
<h4 id="为什么说分块很重要？">为什么说分块很重要？</h4>
<ul>
<li>
<p>分块的目标在于确保每个片段在<strong>保留核心语义</strong>的同时，具备<strong>相对独立的语义完整性</strong>，从而使模型在处理时不必依赖广泛的上下文信息，<strong>增强检索召回的准确性</strong>。</p>
</li>
<li>
<p><strong>分块的重要性在于</strong>它直接影响 RAG 系统的生成质量。首先，合理的分块能够确保<strong>检索到的片段与用户查询信息高度匹配</strong>，避免信息冗余或丢失。</p>
</li>
<li>
<p><strong>好的分块有助于提升生成内容的连贯性</strong>，精心设计的独立语义片段可以<strong>降低模型对上下文的依赖</strong>，从而增强生成的逻辑性与一致性。</p>
</li>
<li>
<p>分块策略的选择还会<strong>影响系统的响应速度与效率</strong>，模型能够更快、更准确地处理和生成内容。</p>
</li>
<li>
<h4 id="分块策略最大的挑战在于确定分块的大小。">分块策略最大的挑战在于确定分块的大小。</h4>
<span id="more"></span>
<ul>
<li>如果<strong>片段过大</strong>，可能导致向量<strong>无法精确捕捉内容的特定细节</strong>并且计算成本增加；</li>
<li>若<strong>片段过小</strong>，则可能丢失上下文信息，导致<strong>句子碎片化和语义不连贯</strong>。</li>
<li>较小的块适用于需要细粒度分析的任务，例如<strong>情感分析</strong>，能够精确捕捉特定短语或句子的细节。</li>
<li>更大的块则更为合适需要保留更广泛上下文的场景，例如<strong>文档摘要或主题检测</strong>。</li>
</ul>
</li>
<li>
<p><img src="https://cdn.jsdelivr.net/gh/hfhfn/image_storage@img/img/image-20250309012438108.png" alt="image-20250309012438108"></p>
</li>
</ul>
</li>
<li>
<h4 id="分块策略">分块策略</h4>
<ul>
<li>
<p>多种分块策略从本质上来看，由以下三个关键组成部分构成：</p>
<ul>
<li><strong>大小</strong>：每个文档块所允许的最大字符数。</li>
<li><strong>重叠</strong>：在相邻数据块之间，重叠字符的数量。</li>
<li><strong>拆分</strong>：通过段落边界、分隔符、标记，或语义边界来确定块边界的位置。</li>
</ul>
</li>
<li>
<p>上述三个组成部分共同决定了分块策略的特性及其适用场景。基于这些组成部分，常见的分块策略包括：</p>
<ul>
<li><strong>固定大小分块（Fixed Size Chunking）、重叠分块（Overlap Chunking）、递归分块（Recursive Chunking）、文档特定分块（Document Specific Chunking）、语义分块（Semantic Chunking）、混合分块（Mix Chunking）</strong>。下面我将对这些策略逐一进行介绍。</li>
<li><img src="https://cdn.jsdelivr.net/gh/hfhfn/image_storage@img/img/image-20250309013703174.png" alt="image-20250309013703174"></li>
<li>我们可以通过<strong>分块可视化</strong>来看一下：（Chunk 切分可视化呈现链接: <a href="https://chunkviz.up.railway.app/%EF%BC%89">https://chunkviz.up.railway.app/）</a></li>
<li>固定大小分块（Fixed Size Chunking）
<ul>
<li>最基本的方法是将文档按固定大小进行分块，通常作为分块策略的基准线使用。</li>
<li>适用场景：适用于格式和大小相似的同质数据集，如新闻文章或博客文章。</li>
<li>问题：可能在句子或段落<strong>中断内容</strong>，导致无意义的文本块，缺乏灵活性，无法适应文本的自然结构。</li>
</ul>
</li>
<li>重叠分块（Overlap Chunking）
<ul>
<li>通过滑动窗口技术切分文本块，使新文本块与前一个块的<strong>内容部分重叠</strong>，从而<strong>保留块边界处的重要上下文信息</strong>，增强系统的语义相关性。</li>
<li>适用场景：需要深入理解语义并保持上下文完整性的文档，如法律文档、技术手册或科研论文。</li>
<li>问题： 增加冗余信息的存储，处理效率降低。</li>
</ul>
</li>
<li>递归分块（Recursive Chunking）
<ul>
<li>通过预定义的文本分隔符（如换行符\n\n、\n ，句号、逗号、感叹号、空格等）迭代地将文本分解为更小的块，以实现段大小的均匀性和语义完整性。此过程中，文本首先按较大的逻辑单元分割（如段落 \n\n），然后逐步递归到较小单元（如句子 \n 和单词），确保<strong>在分块大小限制内保留最强的语义片段</strong>。</li>
<li>适用场景： 这种方法适用于需要<strong>逐层分析</strong>的文本文档或需要分解成长片段、长段落的长文档，如研究报告、法律文档等。</li>
<li>问题： 不过仍有可能在块边界处模糊语义，容易将完整的语义单元切分开。</li>
</ul>
</li>
<li>文档特定分块（Document Specific Chunking）
<ul>
<li>根据文档的格式（如 Markdown、Latex、或编程语言如 Python 等）进行<strong>定制化</strong>分割的技术。</li>
<li>适用场景： 这种方法可以根据特定的文档结构，进行准确的语义内容切分，在编程语言、Markdown、Latex 等结构文档中表现出色。</li>
<li>问题： 但文档特定分块的方式格式依赖性强，不同格式之间的分块策略不通用，并且无法处理格式不规范及混合多种格式的情况。</li>
</ul>
</li>
<li>语义分块（Semantic Chunking）
<ul>
<li>基于文本的自然语言边界（如句子、段落或主题中断）进行分段的技术，需要使用 <strong>NLP 技术根据语义分词分句</strong>，旨在确保每个分块都包含语义连贯的信息单元。</li>
<li>常用的分块策略有 spaCy 和 NLTK 的 NLP 库，spaCy 适用于需要<strong>高效、精准语义切分</strong>的大规模文本处理，NLTK 更<strong>适合教学、研究和需要灵活自定义</strong>的语义切分任务。</li>
<li>适用场景：提高检索结果的相关性和准确性；复杂文档和上下文敏感的精细化分析。</li>
<li>问题：需要额外的计算资源，处理效率较低。</li>
</ul>
</li>
<li>混合分块（Mix Chunking）
<ul>
<li>综合利用不同分块技术的优势，提高分块的精准性和效率。</li>
<li>根据实际业务场景，设计多种分块策略的混合，能够灵活适应各种需求，提供更强大的分块方案。</li>
</ul>
</li>
</ul>
</li>
<li>
<p>上述分块策略在 langchain_text_splitters 库中对应的具体方法类如下：</p>
<ul>
<li>
<p><img src="https://cdn.jsdelivr.net/gh/hfhfn/image_storage@img/img/image-20250309021222817.png" alt="image-20250309021222817"></p>
</li>
<li>
<p>SpacyTextSplitter 和 NLTKTextSplitter 需要额外安装 Python 依赖库，其中 SpacyTextSplitter 还需要按照文档的语言对应安装额外的语言模型。</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">conda activate rag  <span class="comment"># 激活虚拟环境</span></span><br><span class="line">pip install spacy nltk -i https://pypi.tuna.tsinghua.edu.cn/simple</span><br><span class="line">python -m spacy download zh_core_web_sm <span class="comment"># 如果需要进行中文分块，安装spacy中文语言模型</span></span><br><span class="line">python -m spacy download en_core_web_sm <span class="comment"># 如果需要进行英文分块，安装spacy英文语言模型</span></span><br></pre></td></tr></table></figure>
<ul>
<li>导入 langchain.text_splitter 中各种文档分块类代码：</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.text_splitter <span class="keyword">import</span> (</span><br><span class="line">        CharacterTextSplitter,</span><br><span class="line">        RecursiveCharacterTextSplitter,</span><br><span class="line">        MarkdownTextSplitter,</span><br><span class="line">        PythonCodeTextSplitter,</span><br><span class="line">        LatexTextSplitter,</span><br><span class="line">        SpacyTextSplitter,</span><br><span class="line">        NLTKTextSplitter</span><br><span class="line">	) <span class="comment"># 从 langchain.text_splitter 模块中导入各种文档分块类</span></span><br></pre></td></tr></table></figure>
<ul>
<li>
<p>CharacterTextSplitter、RecursiveCharacterTextSplitter、MarkdownTextSplitter、PythonCodeTextSplitter、LatexTextSplitter、NLTKTextSplitter 替换原有 text_splitter 参数的赋值类即可。</p>
</li>
<li>
<p>需要额外处理的是 SpacyTextSplitter，需要参数 pipeline 指定具体的语言模型才可以运行。</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 配置SpacyTextSplitter分割文本块库</span></span><br><span class="line">text_splitter = SpacyTextSplitter(chunk_size=<span class="number">512</span>, chunk_overlap=<span class="number">128</span>, pipeline=<span class="string">&quot;zh_core_web_sm&quot;</span>)</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
</ul>
]]></content>
      <categories>
        <category>AI</category>
        <category>RAG</category>
        <category>索引</category>
        <category>分块策略</category>
      </categories>
      <tags>
        <tag>AI</tag>
        <tag>RAG</tag>
        <tag>索引</tag>
        <tag>分块策略</tag>
        <tag>langchain</tag>
        <tag>Chunk</tag>
      </tags>
  </entry>
  <entry>
    <title>Hello World</title>
    <url>/2025/03/05/hello-world/</url>
    <content><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p>
<span id="more"></span>
<h2 id="Quick-Start">Quick Start</h2>
<h3 id="Create-a-new-post">Create a new post</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p>
<h3 id="Run-server">Run server</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p>
<h3 id="Generate-static-files">Generate static files</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p>
<h3 id="Deploy-to-remote-sites">Deploy to remote sites</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>
]]></content>
  </entry>
  <entry>
    <title>markdown-it 的扩展插件</title>
    <url>/2025/03/09/markdown-it-%E7%9A%84%E6%89%A9%E5%B1%95%E6%8F%92%E4%BB%B6/</url>
    <content><![CDATA[<p>这些插件是 <code>markdown-it</code> 的扩展插件，用于增强 Markdown 的功能。以下是每个插件的功能说明和使用方法：</p>
<hr>
<h3 id="1-markdown-it-footnote">1. <strong>markdown-it-footnote</strong></h3>
<ul>
<li>
<p><strong>功能</strong>：支持脚注功能。</p>
</li>
<li>
<p><strong>用法</strong>：</p>
<figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">这是一个带有脚注的文本[^footnote]。</span><br><span class="line"></span><br><span class="line">[<span class="symbol">^footnote</span>]: <span class="link">这是脚注内容。</span></span><br></pre></td></tr></table></figure>
</li>
<li>
<p><strong>效果</strong>：<br>
这是一个带有脚注的文本<sup class="footnote-ref"><a href="#fn1" id="fnref1">[1]</a></sup>.</p>
</li>
</ul>
<hr>
<span id="more"></span>
<h3 id="2-markdown-it-sub">2. <strong>markdown-it-sub</strong></h3>
<ul>
<li><strong>功能</strong>：支持下标文本。</li>
<li><strong>用法</strong>：<figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">H~2~O</span><br></pre></td></tr></table></figure>
</li>
<li><strong>效果</strong>：<br>
H<sub>2</sub>O</li>
</ul>
<hr>
<h3 id="3-markdown-it-sup">3. <strong>markdown-it-sup</strong></h3>
<ul>
<li><strong>功能</strong>：支持上标文本。</li>
<li><strong>用法</strong>：<figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">2^10^ = 1024</span><br></pre></td></tr></table></figure>
</li>
<li><strong>效果</strong>：<br>
2<sup>10</sup> = 1024</li>
</ul>
<hr>
<h3 id="4-markdown-it-deflist">4. <strong>markdown-it-deflist</strong></h3>
<ul>
<li>
<p><strong>功能</strong>：支持定义列表。</p>
</li>
<li>
<p><strong>用法</strong>：</p>
<figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">术语 1</span><br><span class="line">: 定义 1</span><br><span class="line"></span><br><span class="line">术语 2</span><br><span class="line">: 定义 2</span><br></pre></td></tr></table></figure>
</li>
<li>
<p><strong>效果</strong>：<br>
术语 1<br>
: 定义 1</p>
<dl>
<dt>术语 2</dt>
<dd>定义 2</dd>
</dl>
</li>
</ul>
<hr>
<h3 id="5-markdown-it-abbr">5. <strong>markdown-it-abbr</strong></h3>
<ul>
<li>
<p><strong>功能</strong>：支持缩写词。</p>
</li>
<li>
<p><strong>用法</strong>：</p>
<figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line"><span class="emphasis">*[HTML]: HyperText Markup Language</span></span><br><span class="line"><span class="emphasis">*</span>[W3C]: World Wide Web Consortium</span><br><span class="line"></span><br><span class="line">HTML 是 W3C 的标准。</span><br></pre></td></tr></table></figure>
</li>
<li>
<p><strong>效果</strong>：</p>
<p><abbr title="HyperText Markup Language">HTML</abbr> 是 <abbr title="World Wide Web Consortium">W3C</abbr> 的标准。</p>
</li>
</ul>
<hr>
<h3 id="6-markdown-it-emoji">6. <strong>markdown-it-emoji</strong></h3>
<ul>
<li><strong>功能</strong>：支持 Emoji 表情。</li>
<li><strong>用法</strong>：<figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">:smile: :heart: :rocket:</span><br></pre></td></tr></table></figure>
</li>
<li><strong>效果</strong>：<br>
😄 ❤️ 🚀</li>
</ul>
<hr>
<h3 id="7-markdown-it-container">7. <strong>markdown-it-container</strong></h3>
<ul>
<li>
<p><strong>功能</strong>：支持自定义容器块。</p>
</li>
<li>
<p><strong>用法</strong>：</p>
<figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">::: warning</span><br><span class="line">这是一个警告框。</span><br><span class="line">:::</span><br><span class="line"></span><br><span class="line">::: tip</span><br><span class="line">这是一个提示框。</span><br><span class="line">:::</span><br></pre></td></tr></table></figure>
</li>
<li>
<p><strong>效果</strong>：<br>
::: warning<br>
这是一个警告框。<br>
:::</p>
<p>::: tip<br>
这是一个提示框。<br>
:::</p>
</li>
</ul>
<hr>
<h3 id="8-markdown-it-ins">8. <strong>markdown-it-ins</strong></h3>
<ul>
<li><strong>功能</strong>：支持插入文本（下划线）。</li>
<li><strong>用法</strong>：<figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">++插入的文本++</span><br></pre></td></tr></table></figure>
</li>
<li><strong>效果</strong>：<br>
<ins>插入的文本</ins></li>
</ul>
<hr>
<h3 id="9-markdown-it-mark">9. <strong>markdown-it-mark</strong></h3>
<ul>
<li><strong>功能</strong>：支持高亮文本。</li>
<li><strong>用法</strong>：<figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">==高亮的文本==</span><br></pre></td></tr></table></figure>
</li>
<li><strong>效果</strong>：<br>
<mark>高亮的文本</mark></li>
</ul>
<hr>
<h3 id="10-配置方法">10. <strong>配置方法</strong></h3>
<p>在 <code>_config.yml</code> 中配置 <code>hexo-renderer-markdown-it</code> 插件时，可以启用这些插件。例如：</p>
   <figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">markdown:</span></span><br><span class="line">  <span class="attr">render:</span></span><br><span class="line">    <span class="attr">html:</span> <span class="literal">true</span></span><br><span class="line">    <span class="attr">xhtmlOut:</span> <span class="literal">false</span></span><br><span class="line">    <span class="attr">breaks:</span> <span class="literal">true</span></span><br><span class="line">    <span class="attr">linkify:</span> <span class="literal">true</span></span><br><span class="line">    <span class="attr">typographer:</span> <span class="literal">true</span></span><br><span class="line">    <span class="attr">quotes:</span> <span class="string">&#x27;“”‘’&#x27;</span></span><br><span class="line">  <span class="attr">plugins:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">markdown-it-footnote</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">markdown-it-sub</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">markdown-it-sup</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">markdown-it-deflist</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">markdown-it-abbr</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">markdown-it-emoji</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">markdown-it-container</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">markdown-it-ins</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">markdown-it-mark</span></span><br></pre></td></tr></table></figure>
<hr>
<h3 id="11-安装插件">11. <strong>安装插件</strong></h3>
<p>运行以下命令安装这些插件：</p>
   <figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">pnpm install markdown-it-footnote markdown-it-sub markdown-it-sup markdown-it-deflist markdown-it-abbr markdown-it-emoji markdown-it-container markdown-it-ins markdown-it-mark --save</span><br></pre></td></tr></table></figure>
<hr>
<h3 id="12-总结">12. <strong>总结</strong></h3>
<ul>
<li>这些插件可以增强 Markdown 的功能，例如支持脚注、上下标、定义列表、Emoji 表情等。</li>
<li>在 <code>_config.yml</code> 中配置 <code>hexo-renderer-markdown-it</code> 插件时，启用这些插件即可使用。</li>
</ul>
<hr class="footnotes-sep">
<section class="footnotes">
<ol class="footnotes-list">
<li id="fn1" class="footnote-item"><p>这是脚注内容。 <a href="#fnref1" class="footnote-backref">↩︎</a></p>
</li>
</ol>
</section>
]]></content>
      <categories>
        <category>自媒体</category>
        <category>博客</category>
      </categories>
      <tags>
        <tag>博客</tag>
        <tag>Hexo</tag>
        <tag>Markdown插件</tag>
        <tag>自媒体</tag>
      </tags>
  </entry>
  <entry>
    <title>Text2SQL应用对比</title>
    <url>/2025/03/06/Text2SQL%E5%BA%94%E7%94%A8%E5%AF%B9%E6%AF%94/</url>
    <content><![CDATA[<p>Postgres.new 和 Vanna 是两个不同的工具，分别用于不同的场景和目的。以下是它们的对比：</p>
<hr>
<span id="more"></span>
<h3 id="1-Postgres-new"><strong>1. Postgres.new</strong></h3>
<ul>
<li><strong>类型</strong>：在线工具</li>
<li><strong>用途</strong>：快速创建一个临时的 PostgreSQL 数据库实例，用于测试、演示或学习。</li>
<li><strong>特点</strong>：
<ul>
<li>无需安装或配置，直接在浏览器中使用。</li>
<li>提供临时的数据库实例，通常有时间限制（例如 1 小时）。</li>
<li>适合快速测试 SQL 查询、数据库设计或演示。</li>
<li>支持标准的 PostgreSQL 功能。</li>
</ul>
</li>
<li><strong>适用场景</strong>：
<ul>
<li>快速测试 SQL 查询。</li>
<li>教学或演示 PostgreSQL 功能。</li>
<li>临时需要数据库环境的场景。</li>
</ul>
</li>
</ul>
<hr>
<h3 id="2-Vanna"><strong>2. Vanna</strong></h3>
<ul>
<li><strong>类型</strong>：AI 驱动的工具</li>
<li><strong>用途</strong>：通过自然语言生成 SQL 查询，帮助用户与数据库交互。</li>
<li><strong>特点</strong>：
<ul>
<li>基于 AI 模型（如 OpenAI 的 GPT）生成 SQL。</li>
<li>支持自然语言输入，用户可以用简单的语言描述查询需求。</li>
<li>可以连接到多种数据库（如 PostgreSQL、MySQL、Snowflake 等）。</li>
<li>提供 Python 库，方便集成到数据工作流中。</li>
</ul>
</li>
<li><strong>适用场景</strong>：
<ul>
<li>非技术用户需要查询数据库。</li>
<li>快速生成复杂 SQL 查询。</li>
<li>数据分析师或开发人员希望提高工作效率。</li>
</ul>
</li>
</ul>
<hr>
<h3 id="对比总结"><strong>对比总结</strong></h3>
<table>
<thead>
<tr>
<th>特性</th>
<th>Postgres.new</th>
<th>Vanna</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>类型</strong></td>
<td>在线临时数据库工具</td>
<td>AI 驱动的 SQL 生成工具</td>
</tr>
<tr>
<td><strong>主要用途</strong></td>
<td>创建临时 PostgreSQL 实例</td>
<td>通过自然语言生成 SQL 查询</td>
</tr>
<tr>
<td><strong>用户群体</strong></td>
<td>开发者、测试人员、学习者</td>
<td>数据分析师、非技术用户、开发者</td>
</tr>
<tr>
<td><strong>技术依赖</strong></td>
<td>无需 AI，纯数据库工具</td>
<td>依赖 AI 模型（如 GPT）</td>
</tr>
<tr>
<td><strong>集成能力</strong></td>
<td>无</td>
<td>支持 Python 库，可集成到工作流</td>
</tr>
<tr>
<td><strong>适用场景</strong></td>
<td>测试、演示、学习</td>
<td>数据分析、快速生成 SQL、简化查询</td>
</tr>
</tbody>
</table>
<hr>
<h3 id="选择建议"><strong>选择建议</strong></h3>
<ul>
<li>如果你需要快速创建一个临时的 PostgreSQL 数据库实例进行测试或学习，选择 <strong>Postgres.new</strong>。</li>
<li>如果你希望通过自然语言生成 SQL 查询，简化与数据库的交互，选择 <strong>Vanna</strong>。</li>
</ul>
<p>两者可以结合使用：例如，用 Postgres.new 创建一个临时数据库，然后用 Vanna 生成 SQL 查询并执行。</p>
]]></content>
      <categories>
        <category>AI</category>
        <category>AI工具</category>
      </categories>
      <tags>
        <tag>AI工具</tag>
        <tag>Text2SQL</tag>
        <tag>自然语言操作数据库</tag>
      </tags>
  </entry>
  <entry>
    <title>rag-lesson-1</title>
    <url>/2025/03/05/rag-lesson-1/</url>
    <content><![CDATA[<h1>从 0 到 1 快速搭建 RAG 应用</h1>
<ul>
<li>
<h2 id="技术框架与选型">技术框架与选型</h2>
<ul>
<li>
<h3 id="RAG-技术框架：LangChain">RAG 技术框架：<strong>LangChain</strong></h3>
<ul>
<li>LangChain 是专为开发基于大型语言模型（LLM）应用而设计的全面框架，其核心目标是简化开发者的构建流程，使其能够高效创建 LLM 驱动的应用。</li>
</ul>
</li>
</ul>
<span id="more"></span>
<ul>
<li>
<h3 id="索引流程-文档解析模块：pypdf">索引流程 - 文档解析模块：pypdf</h3>
<ul>
<li>pypdf 是一个开源的 Python 库，专门用于处理 PDF 文档。pypdf 支持 PDF 文档的创建、读取、编辑和转换操作，能够有效提取和处理文本、图像及页面内容。</li>
</ul>
</li>
<li>
<h3 id="索引流程-文档分块模块：RecursiveCharacterTextSplitter">索引流程 - 文档分块模块：RecursiveCharacterTextSplitter</h3>
<ul>
<li>采用 LangChain 默认的文本分割器 -RecursiveCharacterTextSplitter。该分割器通过层次化的分隔符（从双换行符到单字符）拆分文本，旨在保持文本的结构和连贯性，优先考虑自然边界如段落和句子。</li>
</ul>
</li>
<li>
<h3 id="索引-检索流程-向量化模型：BAAI-bge-m3">索引 / 检索流程 - 向量化模型：BAAI/bge-m3</h3>
<ul>
<li>bge-m3 是由北京人工智能研究院（BAAI，智源）开发的开源向量模型。能够提供高精度和高效的中文向量检索。该模型的向量维度为 1024，最大输入长度同样为 8k。</li>
</ul>
</li>
<li>
<h3 id="索引-检索流程-向量库：Faiss">索引 / 检索流程 - 向量库：Faiss</h3>
<ul>
<li>Faiss 全称 Facebook AI Similarity Search，由 Facebook AI Research 团队开源的向量库，因其稳定性和高效性在向量检索领域广受欢迎。</li>
</ul>
</li>
<li>
<h3 id="生成流程-大语言模型：SiliconCloud-硅基流动-的-Qwen-Qwen2-5-7B-Instruct">生成流程 - 大语言模型：SiliconCloud(硅基流动)的 Qwen/Qwen2.5-7B-Instruct</h3>
<ul>
<li>Qwen/Qwen2.5-7B-Instruct 是阿里开源的一款 chat 大语言模型，支持对话、文案创作、逻辑推理、以及多语言处理，在模型性能和工程应用中表现出色。</li>
</ul>
</li>
<li>
<h3 id="上述选型在-RAG-流程图中的应用如下所示：">上述选型在 RAG 流程图中的应用如下所示：</h3>
<p><img src="https://cdn.jsdelivr.net/gh/hfhfn/image_storage@img/img/RAG%E6%B5%81%E7%A8%8B.png" alt="RAG流程"></p>
<ul>
<li>LangChain：提供用于构建 LLM RAG 的应用程序框架。</li>
<li>索引流程：使用 pypdf 对文档进行解析并提取信息；随后，采用 RecursiveCharacterTextSplitter 对文档内容进行分块（chunks）；最后，利用 bge-3m 将分块内容进行向量化处理，并将生成的向量存储在 Faiss 向量库中。</li>
<li>检索流程：使用 bge-3m 对用户的查询（Query）进行向量化处理；然后，通过 Faiss 向量库对查询向量和文本块向量进行相似度匹配，从而检索出与用户查询最相似的前 top-k 个文本块（chunk）。</li>
<li>生成流程：通过设定提示模板（Prompt），将用户的查询与检索到的参考文本块组合输入到 Qwen 大模型中，生成最终的 RAG 回答。</li>
</ul>
</li>
</ul>
</li>
<li>
<h2 id="开发环境与技术库">开发环境与技术库</h2>
<ul>
<li>
<h3 id="准备windows系统，-pycharm开发工具，-Miniconda（python环境管理工具）">准备windows系统， pycharm开发工具， Miniconda（python环境管理工具）</h3>
</li>
<li>
<h3 id="创建并激活虚拟环境">创建并激活虚拟环境</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">conda create -n rag python=<span class="number">3.11</span>  <span class="comment"># 创建名为rag的虚拟环境</span></span><br><span class="line">conda activate rag  <span class="comment"># 激活虚拟环境</span></span><br></pre></td></tr></table></figure>
</li>
<li>
<h3 id="安装技术依赖库">安装技术依赖库</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pip install langchain langchain_community pypdf sentence-transformers faiss-cpu</span><br><span class="line"><span class="comment"># 无法安装，可以使用国内镜像源，命令如下：</span></span><br><span class="line">pip install langchain langchain_community pypdf sentence-transformers faiss-cpu -i https://pypi.tuna.tsinghua.edu.cn/simple</span><br></pre></td></tr></table></figure>
</li>
<li>
<h3 id="课程中用到的代码和pdf文件分享在github上：">课程中用到的代码和pdf文件分享在github上：</h3>
<ol>
<li>[x] <a href="https://github.com/hfhfn/rag_learning">https://github.com/hfhfn/rag_learning</a></li>
</ol>
</li>
</ul>
</li>
</ul>
]]></content>
      <categories>
        <category>AI</category>
        <category>RAG</category>
      </categories>
      <tags>
        <tag>RAG</tag>
        <tag>AI,</tag>
      </tags>
  </entry>
  <entry>
    <title>扩散模型和 自回归模型的对比</title>
    <url>/2025/03/06/%E6%89%A9%E6%95%A3%E6%A8%A1%E5%9E%8B%E5%92%8C-%E8%87%AA%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%AF%B9%E6%AF%94/</url>
    <content><![CDATA[<p>扩散模型（Diffusion Models）和自回归模型（Autoregressive Models）是生成模型中的两种重要方法，广泛应用于图像、文本和音频生成任务。它们各有特点，适用于不同的场景。</p>
<hr>
<span id="more"></span>
<h3 id="1-扩散模型（Diffusion-Models）"><strong>1. 扩散模型（Diffusion Models）</strong></h3>
<p>扩散模型是一种基于概率的生成模型，其核心思想是通过逐步添加噪声将数据分布转化为简单分布（如高斯分布），然后学习如何逆向去噪以生成新数据。</p>
<h4 id="核心思想"><strong>核心思想</strong></h4>
<ol>
<li>
<p><strong>前向过程（Forward Process）</strong>：</p>
<ul>
<li>
<p>数据（如图像）通过逐步添加高斯噪声被破坏，最终变成一个纯噪声分布。</p>
</li>
<li>
<p>这个过程是固定的，通常定义为马尔可夫链，每一步都添加少量噪声。</p>
</li>
<li>
<p>数学上，前向过程可以表示为：</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>q</mi><mo>(</mo><msub><mi>x</mi><mi>t</mi></msub><mi mathvariant="normal">∣</mi><msub><mi>x</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub><mo>)</mo><mo>=</mo><mrow><mi mathvariant="script">N</mi></mrow><mo>(</mo><msub><mi>x</mi><mi>t</mi></msub><mo separator="true">;</mo><msqrt><mrow><mn>1</mn><mo>−</mo><msub><mi>β</mi><mi>t</mi></msub></mrow></msqrt><msub><mi>x</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub><mo separator="true">,</mo><msub><mi>β</mi><mi>t</mi></msub><mi>I</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">q(x_t | x_{t-1}) = \mathcal{N}(x_t; \sqrt{1-\beta_t} x_{t-1}, \beta_t I)
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.9838800000000001em;"></span><span class="strut bottom" style="height:1.24001em;vertical-align:-0.2561299999999999em;"></span><span class="base displaystyle textstyle uncramped"><span class="mord mathit" style="margin-right:0.03588em;">q</span><span class="mopen">(</span><span class="mord"><span class="mord mathit">x</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathit">t</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mord mathrm">∣</span><span class="mord"><span class="mord mathit">x</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord scriptstyle cramped"><span class="mord mathit">t</span><span class="mbin">−</span><span class="mord mathrm">1</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mclose">)</span><span class="mrel">=</span><span class="mord displaystyle textstyle uncramped"><span class="mord mathcal" style="margin-right:0.14736em;">N</span></span><span class="mopen">(</span><span class="mord"><span class="mord mathit">x</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathit">t</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mpunct">;</span><span class="sqrt mord"><span class="sqrt-sign" style="top:-0.09388000000000007em;"><span class="style-wrap reset-textstyle textstyle uncramped"><span class="delimsizing size1">√</span></span></span><span class="vlist"><span style="top:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:1em;">​</span></span><span class="mord displaystyle textstyle cramped"><span class="mord mathrm">1</span><span class="mbin">−</span><span class="mord"><span class="mord mathit" style="margin-right:0.05278em;">β</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:-0.05278em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathit">t</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span><span style="top:-0.90388em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:1em;">​</span></span><span class="reset-textstyle textstyle uncramped sqrt-line"></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:1em;">​</span></span>​</span></span></span><span class="mord"><span class="mord mathit">x</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord scriptstyle cramped"><span class="mord mathit">t</span><span class="mbin">−</span><span class="mord mathrm">1</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mpunct">,</span><span class="mord"><span class="mord mathit" style="margin-right:0.05278em;">β</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:-0.05278em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathit">t</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mord mathit" style="margin-right:0.07847em;">I</span><span class="mclose">)</span></span></span></span></span></p>
<p>其中，(x_t) 是第 (t) 步的噪声数据，(\beta_t) 是噪声的方差。</p>
<p>其中，(x_t) 是第 (t) 步的噪声数据，(\beta_t) 是噪声的方差。</p>
</li>
</ul>
</li>
<li>
<p><strong>逆向过程（Reverse Process）</strong>：</p>
<ul>
<li>模型学习如何从噪声数据逐步去噪，恢复出原始数据分布。</li>
<li>逆向过程通常通过神经网络参数化，学习每一步的条件分布：<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>p</mi><mi>θ</mi></msub><mo>(</mo><msub><mi>x</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub><mi mathvariant="normal">∣</mi><msub><mi>x</mi><mi>t</mi></msub><mo>)</mo></mrow><annotation encoding="application/x-tex">p_\theta(x_{t-1} | x_t)
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base displaystyle textstyle uncramped"><span class="mord"><span class="mord mathit">p</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathit" style="margin-right:0.02778em;">θ</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathit">x</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord scriptstyle cramped"><span class="mord mathit">t</span><span class="mbin">−</span><span class="mord mathrm">1</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mord mathrm">∣</span><span class="mord"><span class="mord mathit">x</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathit">t</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mclose">)</span></span></span></span></span></p>
</li>
</ul>
</li>
</ol>
<ul>
<li>目标是最大化数据似然，通常通过变分推断优化。</li>
</ul>
<ol start="3">
<li><strong>训练目标</strong>：
<ul>
<li>扩散模型的训练目标是优化逆向过程的参数，使其能够准确地从噪声数据中恢复原始数据。</li>
<li>常用的损失函数是基于均方误差（MSE）的去噪目标。</li>
</ul>
</li>
</ol>
<h4 id="优点"><strong>优点</strong></h4>
<ul>
<li>生成质量高：扩散模型在图像生成任务中表现出色，生成的图像细节丰富。</li>
<li>训练稳定：相比于GANs，扩散模型的训练过程更加稳定。</li>
<li>可解释性强：前向和逆向过程具有清晰的数学定义。</li>
</ul>
<h4 id="缺点"><strong>缺点</strong></h4>
<ul>
<li>生成速度慢：由于需要逐步去噪，生成过程通常较慢。</li>
<li>计算成本高：训练和推理过程需要较多的计算资源。</li>
</ul>
<h4 id="应用"><strong>应用</strong></h4>
<ul>
<li>图像生成（如DALL·E 2、Stable Diffusion）</li>
<li>音频生成</li>
<li>数据去噪</li>
</ul>
<hr>
<h3 id="2-自回归模型（Autoregressive-Models）"><strong>2. 自回归模型（Autoregressive Models）</strong></h3>
<p>自回归模型是一种基于序列的生成模型，其核心思想是利用序列中前面的元素预测后面的元素。它假设当前数据点只依赖于之前的数据点。</p>
<h4 id="核心思想-2"><strong>核心思想</strong></h4>
<ol>
<li>
<p><strong>序列建模</strong>：</p>
<ul>
<li>数据被看作一个序列（如文本、音频或图像的像素序列）。</li>
<li>模型通过条件概率分布逐步生成序列中的每个元素：<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>p</mi><mo>(</mo><mi>x</mi><mo>)</mo><mo>=</mo><msubsup><mo>∏</mo><mrow><mi>t</mi><mo>=</mo><mn>1</mn></mrow><mi>T</mi></msubsup><mi>p</mi><mo>(</mo><msub><mi>x</mi><mi>t</mi></msub><mi mathvariant="normal">∣</mi><msub><mi>x</mi><mrow><mo>&lt;</mo><mi>t</mi></mrow></msub><mo>)</mo></mrow><annotation encoding="application/x-tex">p(x) = \prod_{t=1}^T p(x_t | x_{&lt;t})
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:1.8283360000000002em;"></span><span class="strut bottom" style="height:3.0954490000000003em;vertical-align:-1.267113em;"></span><span class="base displaystyle textstyle uncramped"><span class="mord mathit">p</span><span class="mopen">(</span><span class="mord mathit">x</span><span class="mclose">)</span><span class="mrel">=</span><span class="mop op-limits"><span class="vlist"><span style="top:1.1671129999999998em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord scriptstyle cramped"><span class="mord mathit">t</span><span class="mrel">=</span><span class="mord mathrm">1</span></span></span></span><span style="top:-0.000005000000000143778em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span><span class="op-symbol large-op mop">∏</span></span></span><span style="top:-1.2500050000000003em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle uncramped"><span class="mord mathit" style="margin-right:0.13889em;">T</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mord mathit">p</span><span class="mopen">(</span><span class="mord"><span class="mord mathit">x</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathit">t</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mord mathrm">∣</span><span class="mord"><span class="mord mathit">x</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord scriptstyle cramped"><span class="mrel">&lt;</span><span class="mord mathit">t</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mclose">)</span></span></span></span></span></p>
其中，(x_t) 是序列中的第 (t) 个元素，(x_{&lt;t}) 是之前的所有元素。</li>
</ul>
</li>
<li>
<p><strong>条件概率建模</strong>：</p>
<ul>
<li>使用神经网络（如RNN、LSTM、Transformer）建模条件概率分布 (p(x_t | x_{&lt;t}))。</li>
<li>例如，在文本生成中，模型根据前面的单词预测下一个单词。</li>
</ul>
</li>
<li>
<p><strong>训练目标</strong>：</p>
<ul>
<li>自回归模型的训练目标是最大化序列的似然函数，通常通过交叉熵损失优化。</li>
</ul>
</li>
</ol>
<h4 id="优点-2"><strong>优点</strong></h4>
<ul>
<li>灵活性高：可以建模任意长度的序列。</li>
<li>生成质量好：在文本生成和语音合成等任务中表现优异。</li>
<li>可扩展性强：结合Transformer等强大架构，能够处理长序列数据。</li>
</ul>
<h4 id="缺点-2"><strong>缺点</strong></h4>
<ul>
<li>生成速度慢：由于序列是逐步生成的，生成过程较慢。</li>
<li>长程依赖问题：早期的自回归模型（如RNN）难以捕捉长程依赖，但Transformer部分解决了这一问题。</li>
</ul>
<h4 id="应用-2"><strong>应用</strong></h4>
<ul>
<li>文本生成（如GPT系列）</li>
<li>语音合成（如WaveNet）</li>
<li>图像生成（如PixelRNN、PixelCNN）</li>
</ul>
<hr>
<h3 id="3-扩散模型-vs-自回归模型"><strong>3. 扩散模型 vs 自回归模型</strong></h3>
<table>
<thead>
<tr>
<th>特性</th>
<th>扩散模型</th>
<th>自回归模型</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>生成方式</strong></td>
<td>逐步去噪</td>
<td>逐步预测序列</td>
</tr>
<tr>
<td><strong>生成速度</strong></td>
<td>较慢</td>
<td>较慢</td>
</tr>
<tr>
<td><strong>训练稳定性</strong></td>
<td>高</td>
<td>中等（取决于架构）</td>
</tr>
<tr>
<td><strong>建模能力</strong></td>
<td>适合连续数据（如图像）</td>
<td>适合离散数据（如文本）</td>
</tr>
<tr>
<td><strong>计算成本</strong></td>
<td>高</td>
<td>中等</td>
</tr>
<tr>
<td><strong>应用领域</strong></td>
<td>图像生成、去噪</td>
<td>文本生成、语音合成</td>
</tr>
</tbody>
</table>
<hr>
<h3 id="4-结合与改进"><strong>4. 结合与改进</strong></h3>
<p>近年来，研究者尝试结合扩散模型和自回归模型的优点。例如：</p>
<ul>
<li>在图像生成中，使用自回归模型生成低分辨率图像，再用扩散模型细化细节。</li>
<li>在文本生成中，使用扩散模型生成隐变量，再用自回归模型生成文本。</li>
</ul>
<p>这些方法旨在提高生成质量和效率，同时降低计算成本。</p>
<hr>
<p>总结来说，扩散模型和自回归模型各有优劣，适用于不同的任务。扩散模型在图像生成中表现突出，而自回归模型在文本生成中占据主导地位。随着研究的深入，两者的结合可能会推动生成模型的发展。</p>
]]></content>
      <categories>
        <category>AI</category>
        <category>大模型</category>
      </categories>
      <tags>
        <tag>AI</tag>
        <tag>生成模型方法</tag>
        <tag>大模型</tag>
      </tags>
  </entry>
  <entry>
    <title>翻墙机场推荐（魔法上网）</title>
    <url>/2025/03/05/%E7%BF%BB%E5%A2%99%E6%9C%BA%E5%9C%BA%E6%8E%A8%E8%8D%90%EF%BC%88%E9%AD%94%E6%B3%95%E4%B8%8A%E7%BD%91%EF%BC%89/</url>
    <content><![CDATA[<h2 id="暂时推荐这两个机场（在没有魔法的情况下网站可以登录）">暂时推荐这两个机场（在没有魔法的情况下网站可以登录）</h2>
<h4 id="1-费用自己看着选，贵的速率和稳定性都好一些">1. 费用自己看着选，贵的速率和稳定性都好一些</h4>
<h4 id="2-如果大家有好的机场也可以给我推荐一下（最好在没有魔法时可以登录）">2. 如果大家有好的机场也可以给我推荐一下（最好在没有魔法时可以登录）</h4>
<span id="more"></span>
<ul>
<li>
<p>第一个 牡牛网：<a href="https://xn--11xxa.com/auth/register?code=mdSU">https://牧牛.com/auth/register?code=mdSU</a></p>
<ul>
<li>
<p>邀请码：mdSU</p>
</li>
<li>
<p>推荐安装网页底部的Clash软件</p>
<ul>
<li><img src="https://cdn.jsdelivr.net/gh/hfhfn/image_storage@img/img/image-20250305165344389.png" alt="image-20250305165344389"></li>
</ul>
</li>
<li>
<p>进入页面有详细安装教程，按照步骤操作就行</p>
</li>
<li>
<p>资费：</p>
<ul>
<li><img src="https://cdn.jsdelivr.net/gh/hfhfn/image_storage@img/img/image-20250305170236304.png" alt="image-20250305170236304"></li>
</ul>
</li>
</ul>
</li>
<li>
<p>第二个 Radial VPN: <a href="https://radialvpn.io/?invite=z0m5v9">https://radialvpn.io/?invite=z0m5v9</a></p>
<ul>
<li>下载官网软件按着操作就行</li>
<li>资费：
<ul>
<li><img src="https://cdn.jsdelivr.net/gh/hfhfn/image_storage@img/img/image-20250305170103021.png" alt="image-20250305170103021"></li>
</ul>
</li>
</ul>
</li>
</ul>
]]></content>
      <categories>
        <category>工具</category>
        <category>网络</category>
      </categories>
      <tags>
        <tag>翻墙机场,</tag>
        <tag>魔法上网</tag>
      </tags>
  </entry>
</search>
